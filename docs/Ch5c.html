<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Powered by Linear Algebra - 9&nbsp; Shrinkage Estimators</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./Ch6a.html" rel="next">
<link href="./Ch5b.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./Ch5c.html"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Shrinkage Estimators</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Powered by Linear Algebra</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">index.html</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Matrices and Vectors</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Matrix Inverse</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch2a.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Covariance Matrices, MV Normal Distribution, Delta Method</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Linear Statistical Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Matrix Rank</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch5a.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Vector Spaces</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch5b.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Inner Product Spaces</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch5c.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Shrinkage Estimators</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch6a.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Eigenanalysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch6b.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Principal Components</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch6c.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Singular Value Decomposition</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch6d.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Pseudoinverse and Double Descent</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch7a.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Recommender Systems</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch8a.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Neural Networks</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-nearly" id="toc-sec-nearly" class="nav-link active" data-scroll-target="#sec-nearly"><span class="header-section-number">9.1</span> Multicollinearity</a></li>
  <li><a href="#sec-millionsong" id="toc-sec-millionsong" class="nav-link" data-scroll-target="#sec-millionsong"><span class="header-section-number">9.2</span> Example: Million Song Dataset</a></li>
  <li><a href="#ridge-regression" id="toc-ridge-regression" class="nav-link" data-scroll-target="#ridge-regression"><span class="header-section-number">9.3</span> Ridge Regression</a>
  <ul class="collapse">
  <li><a href="#the-ridge-solution" id="toc-the-ridge-solution" class="nav-link" data-scroll-target="#the-ridge-solution"><span class="header-section-number">9.3.1</span> The ridge solution</a></li>
  <li><a href="#sec-matform" id="toc-sec-matform" class="nav-link" data-scroll-target="#sec-matform"><span class="header-section-number">9.3.2</span> Matrix formulation</a></li>
  <li><a href="#example-million-song-dataset" id="toc-example-million-song-dataset" class="nav-link" data-scroll-target="#example-million-song-dataset"><span class="header-section-number">9.3.3</span> Example: Million Song dataset</a></li>
  </ul></li>
  <li><a href="#sec-xval" id="toc-sec-xval" class="nav-link" data-scroll-target="#sec-xval"><span class="header-section-number">9.4</span> Cross-Validation</a></li>
  <li><a href="#sec-pgtn" id="toc-sec-pgtn" class="nav-link" data-scroll-target="#sec-pgtn"><span class="header-section-number">9.5</span> Modern View</a></li>
  <li><a href="#formalizing-the-notion-of-shrinkage" id="toc-formalizing-the-notion-of-shrinkage" class="nav-link" data-scroll-target="#formalizing-the-notion-of-shrinkage"><span class="header-section-number">9.6</span> Formalizing the Notion of Shrinkage</a>
  <ul class="collapse">
  <li><a href="#shrinkage-through-length-penalization" id="toc-shrinkage-through-length-penalization" class="nav-link" data-scroll-target="#shrinkage-through-length-penalization"><span class="header-section-number">9.6.1</span> Shrinkage through length penalization</a></li>
  <li><a href="#shrinkage-through-length-limitation" id="toc-shrinkage-through-length-limitation" class="nav-link" data-scroll-target="#shrinkage-through-length-limitation"><span class="header-section-number">9.6.2</span> Shrinkage through length limitation</a></li>
  </ul></li>
  <li><a href="#the-lasso" id="toc-the-lasso" class="nav-link" data-scroll-target="#the-lasso"><span class="header-section-number">9.7</span> The LASSO</a>
  <ul class="collapse">
  <li><a href="#properties" id="toc-properties" class="nav-link" data-scroll-target="#properties"><span class="header-section-number">9.7.1</span> Properties</a></li>
  </ul></li>
  <li><a href="#ridge-vs.-lasso-for-dimension-reduction" id="toc-ridge-vs.-lasso-for-dimension-reduction" class="nav-link" data-scroll-target="#ridge-vs.-lasso-for-dimension-reduction"><span class="header-section-number">9.8</span> Ridge vs.&nbsp;LASSO for Dimension Reduction</a>
  <ul class="collapse">
  <li><a href="#geometric-view" id="toc-geometric-view" class="nav-link" data-scroll-target="#geometric-view"><span class="header-section-number">9.8.1</span> Geometric view</a></li>
  <li><a href="#implication-for-dimension-reduction." id="toc-implication-for-dimension-reduction." class="nav-link" data-scroll-target="#implication-for-dimension-reduction."><span class="header-section-number">9.8.2</span> Implication for dimension reduction.</a></li>
  <li><a href="#avoidance-of-overfitting-without-dimension-reduction" id="toc-avoidance-of-overfitting-without-dimension-reduction" class="nav-link" data-scroll-target="#avoidance-of-overfitting-without-dimension-reduction"><span class="header-section-number">9.8.3</span> Avoidance of overfitting <em>without</em> dimension reduction</a></li>
  </ul></li>
  <li><a href="#sec-useall" id="toc-sec-useall" class="nav-link" data-scroll-target="#sec-useall"><span class="header-section-number">9.9</span> Example: NYC Taxi Data</a></li>
  <li><a href="#a-warning" id="toc-a-warning" class="nav-link" data-scroll-target="#a-warning"><span class="header-section-number">9.10</span> A Warning</a></li>
  <li><a href="#your-turn" id="toc-your-turn" class="nav-link" data-scroll-target="#your-turn"><span class="header-section-number">9.11</span> Your Turn</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Shrinkage Estimators</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<div style="page-break-after: always;"></div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Goals of this chapter:
</div>
</div>
<div class="callout-body-container callout-body">
<p>In the previous chapter, we introduced the norm of a vector. In many data science applications, solutions with smaller norms may be more accurate. This point is explored here.</p>
</div>
</div>
<section id="sec-nearly" class="level2" data-number="9.1">
<h2 data-number="9.1" class="anchored" data-anchor-id="sec-nearly"><span class="header-section-number">9.1</span> Multicollinearity</h2>
<p>The term <em>multicollinearity</em> refers to settings in which the following concerns arise:</p>
<ul>
<li><p>One column of the matrix <span class="math inline">\(A\)</span> in <a href="Ch3.html#eq-linregformula">Equation&nbsp;<span>5.4</span></a> is nearly equal to some linear combination of the others.</p></li>
<li><p>Thus <span class="math inline">\(A\)</span> is nearly not of full rank.</p></li>
<li><p>Thus <span class="math inline">\(A'A\)</span> is nearly not of full rank.</p></li>
<li><p>Thus <span class="math inline">\(\widehat{\beta}\)</span> is unstable, in the form of high variance.</p></li>
</ul>
<p>(Technically, the above conditions refer to <em>approximate</em> multicollinearity, with the exact version consisting of the first three bullet points, minus the word “nearly.” However, informally, the term <em>multicollinearity</em> is usually taken to mean the approximate condition.)</p>
<p>That latter point is often quantified by the <em>Variance Inflation Factor</em>. To motivate it, consider the “R-squared” value from linear regression analyis, which is the squared correlation between “Y” and predicted “Y”. Let <span class="math inline">\(R^2_j\)</span> denote that measure in the case of predicting column <span class="math inline">\(j\)</span> of <span class="math inline">\(A\)</span> from the other columns. The quantity</p>
<p><span class="math display">\[
VIF_j = \frac{1}{1-R^2_j}
\]</span></p>
<p>then measures the negative impact due to multicollinearity on estimating <span class="math inline">\(\widehat{\beta}_j\)</span>. The intuition is that, say, column 3 of <span class="math inline">\(A\)</span> can be predicte well using a linear model, then that column is approximately equal to a linear combination of the other columns. This is worrisome in light of the problems described above.</p>
<p>Needless to say, the word “nearly” above, e.g.&nbsp;in “nearly not of full rank,” is vague, and leaves open the question of “What can we do about it?” We will present several answers to these questions in this and the succeeding chapters.</p>
</section>
<section id="sec-millionsong" class="level2" data-number="9.2">
<h2 data-number="9.2" class="anchored" data-anchor-id="sec-millionsong"><span class="header-section-number">9.2</span> Example: Million Song Dataset</h2>
<p>Let’s consider the Million Song Dataset, varous versions of which are on the Web.</p>
<p>Ours is a 50,000-line subset of the one with 515345 rows and 91 columns. The first column is the year of release, followed by 90 columns of various audio measurements. The goal is to predict the year, <strong>V1</strong>, from the audio variables <strong>V2</strong> through <strong>V91</strong>.</p>
<p>The function <strong>regclass::VIF</strong> will compute the VIF values for us.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(WackyData)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(MillSong50K) <span class="co"># loads s50</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>lmout <span class="ot">&lt;-</span> <span class="fu">lm</span>(V1 <span class="sc">~</span> .,<span class="at">data=</span>s50)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(regclass)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">VIF</span>(lmout)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>      V2       V3       V4       V5       V6       V7       V8       V9 
3.215081 2.596474 4.236853 7.414375 1.534492 5.844729 2.794018 3.192805 
     V10      V11      V12      V13      V14      V15      V16      V17 
2.072851 3.673590 4.705886 1.708520 2.446279 2.827296 3.672250 7.409782 
     V18      V19      V20      V21      V22      V23      V24      V25 
2.634033 9.472261 4.217311 7.147952 5.122114 7.984860 9.675134 3.591586 
     V26      V27      V28      V29      V30      V31      V32      V33 
1.818596 1.758043 3.879968 1.663670 2.108174 2.321385 2.056017 1.854913 
     V34      V35      V36      V37      V38      V39      V40      V41 
3.011534 2.040587 2.760111 2.879667 1.918229 2.176048 2.074103 1.946859 
     V42      V43      V44      V45      V46      V47      V48      V49 
1.704259 2.138794 1.690651 1.556782 1.817380 3.000759 1.547592 2.140282 
     V50      V51      V52      V53      V54      V55      V56      V57 
2.496121 1.612253 2.042571 2.208492 1.723669 2.024290 2.016403 2.033654 
     V58      V59      V60      V61      V62      V63      V64      V65 
2.004260 2.998469 2.074152 3.410124 2.153116 1.378160 3.270617 1.502543 
     V66      V67      V68      V69      V70      V71      V72      V73 
2.581171 1.725809 2.167673 2.379354 2.062862 1.703360 2.036596 1.984427 
     V74      V75      V76      V77      V78      V79      V80      V81 
2.557163 1.465020 1.515436 2.260728 1.840509 2.078497 3.604771 1.595064 
     V82      V83      V84      V85      V86      V87      V88      V89 
2.528307 2.005876 2.283956 1.448379 1.895053 1.601004 1.581099 2.252362 
     V90      V91 
1.332590 1.570891 </code></pre>
</div>
</div>
<p>As a rough guide, values of VIF about 5.0 are considered concerning by many analysts. Under that criterion, variables <strong>V5</strong>, <strong>V7</strong>, <strong>V17</strong> and so on look troublesome.</p>
<p>What can be done? One simple approach would be to delete those columns from the dataset. This is indeed is a common solution, but another is <em>ridge regression</em>, which we present next.</p>
</section>
<section id="ridge-regression" class="level2 page-columns page-full" data-number="9.3">
<h2 data-number="9.3" class="anchored" data-anchor-id="ridge-regression"><span class="header-section-number">9.3</span> Ridge Regression</h2>
<div class="page-columns page-full"><p>In seminal paper, Hoerl and Kennard discussed the problem of <em>multicollinearity</em> of predictor variables in a linear model.</p><div class="no-row-height column-margin column-container"><span class=""><em>Technometrids</em>, Februaru1970</span></div></div>
<section id="the-ridge-solution" class="level3" data-number="9.3.1">
<h3 data-number="9.3.1" class="anchored" data-anchor-id="the-ridge-solution"><span class="header-section-number">9.3.1</span> The ridge solution</h3>
<p>Their solution is simple; Add some quantity to the diagonal of <span class="math inline">\(A'A\)</span>. Specifically, <a href="Ch3.html#eq-linregformula">Equation&nbsp;<span>5.4</span></a> now becomes</p>
<p><span id="eq-ridge"><span class="math display">\[
\widehat{\beta} - (A'A + \lambda I)^{-1} A'S
\tag{9.1}\]</span></span></p>
<p>where <span class="math inline">\(\lambda\)</span> is a positive number chosen by the analyst.</p>
<p>Here <span class="math inline">\(A\)</span> has dimensions <span class="math inline">\(n \textrm{ x } p\)</span>, and <span class="math inline">\(I\)</span> is the <span class="math inline">\(p \textrm{ x } p\)</span> identity matrix.</p>
</section>
<section id="sec-matform" class="level3" data-number="9.3.2">
<h3 data-number="9.3.2" class="anchored" data-anchor-id="sec-matform"><span class="header-section-number">9.3.2</span> Matrix formulation</h3>
<p>Using partitioned matrices helps understand ridge. Replace <span class="math inline">\(A\)</span> and <span class="math inline">\(S\)</span> by</p>
<p><span class="math display">\[
A_{new} =
\left (
\begin{array}{r}
A \\
\lambda I \\
\end{array}
\right )
\]</span></p>
<p>and</p>
<p><span class="math display">\[
S_{new} =
\left (
\begin{array}{r}
S \\
0 \\
\end{array}
\right )
\]</span></p>
<p>where 0 means <span class="math inline">\(p\)</span> 0s. In essence, we are adding artificial data here, consisting of <span class="math inline">\(p\)</span> new rows to <span class="math inline">\(A\)</span>, and <span class="math inline">\(p\)</span> new elements to <span class="math inline">\(S\)</span>. So <a href="#eq-ridge">Equation&nbsp;<span>9.1</span></a> is just the result of applying <a href="Ch3.html#eq-linregformula">Equation&nbsp;<span>5.4</span></a> to <span class="math inline">\(A_{new}\)</span> and <span class="math inline">\(S_{new}\)</span>.</p>
<p>Loosely speaking, we can think of the addition of <span class="math inline">\(\lambda I\)</span> to <span class="math inline">\(A'A\)</span> makes the latter “larger”, and thus its inverse smaller. In other words, we are “shrinking” <span class="math inline">\(\widehat{\beta}\)</span> towards 0. This effect is made even stronger by the fact that we added 0s data to <span class="math inline">\(S\)</span>. This will be made more precise below.</p>
</section>
<section id="example-million-song-dataset" class="level3" data-number="9.3.3">
<h3 data-number="9.3.3" class="anchored" data-anchor-id="example-million-song-dataset"><span class="header-section-number">9.3.3</span> Example: Million Song dataset</h3>
<p>We will use <strong>glmnet</strong>, one of the most widely-used R package.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(glmnet)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> s50[,<span class="sc">-</span><span class="dv">1</span>]</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> s50[,<span class="dv">1</span>]</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>glmOut <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(x,y,</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>             <span class="at">alpha=</span><span class="dv">0</span>,  <span class="co"># ridge</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>             <span class="at">lambda=</span><span class="fl">0.1</span>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(glmOut)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>91 x 1 sparse Matrix of class "dgCMatrix"
                       s0
(Intercept)  1.952611e+03
V2           8.573258e-01
V3          -5.589618e-02
V4          -4.521365e-02
V5           8.939743e-04
V6          -9.630525e-03
V7          -2.075296e-01
V8          -4.753624e-03
V9          -9.733144e-02
V10         -6.383153e-02
V11          2.778348e-02
V12         -1.486791e-01
V13         -1.326579e-02
V14          4.756877e-02
V15          3.197157e-04
V16         -4.765018e-04
V17          4.951670e-04
V18          5.276124e-04
V19          1.254372e-03
V20          1.518736e-03
V21          2.206416e-03
V22         -4.304329e-04
V23          5.792964e-04
V24          7.717453e-03
V25          3.205090e-03
V26         -3.527333e-03
V27          4.785205e-05
V28          1.510325e-03
V29          2.996810e-04
V30          6.384049e-04
V31         -2.560997e-04
V32         -4.861561e-04
V33         -6.250266e-04
V34         -3.757523e-03
V35          3.563733e-04
V36          1.288622e-03
V37         -4.417041e-03
V38         -2.502325e-04
V39          9.405005e-04
V40          1.490186e-03
V41         -1.534097e-03
V42         -1.510983e-03
V43         -1.777780e-03
V44         -1.814201e-03
V45         -1.865966e-03
V46         -1.107727e-03
V47          5.906898e-03
V48          6.578124e-04
V49         -2.040170e-03
V50          4.795372e-04
V51          1.162657e-03
V52          6.164815e-04
V53         -9.613775e-04
V54          1.571230e-03
V55         -1.230929e-03
V56         -1.395143e-03
V57          2.158453e-04
V58         -1.975641e-03
V59          2.039760e-03
V60         -1.302405e-03
V61          6.875221e-04
V62         -3.480975e-03
V63         -3.285816e-03
V64         -9.199332e-03
V65          1.283424e-03
V66         -1.444237e-03
V67         -5.957302e-05
V68          1.139299e-03
V69         -9.805816e-04
V70         -3.734949e-03
V71         -5.127353e-03
V72         -1.071399e-03
V73          1.808175e-04
V74         -1.034781e-05
V75          4.315147e-03
V76          3.382526e-03
V77          1.111779e-02
V78          3.162072e-04
V79         -4.565407e-03
V80          3.729735e-05
V81          2.362107e-04
V82         -9.349464e-04
V83         -2.846584e-04
V84          1.439897e-03
V85          1.360484e-03
V86          2.442744e-02
V87         -6.838186e-04
V88          8.555403e-04
V89         -3.329155e-02
V90         -1.793489e-03
V91         -3.614719e-05</code></pre>
</div>
</div>
<p>We had earlier flagged variable <span class="math inline">\(V5\)</span> as causing multicollinearity. As noted then, we could simply exclude it, but here under ridge, we see that it has been assigned a very small regression coefficient compared to most others.</p>
</section>
</section>
<section id="sec-xval" class="level2" data-number="9.4">
<h2 data-number="9.4" class="anchored" data-anchor-id="sec-xval"><span class="header-section-number">9.4</span> Cross-Validation</h2>
<p>So, how do we choose <span class="math inline">\(\lambda\)</span>?</p>
<p>A common way to choose among models is <em>cross-validation</em>: We set aside a subset of the data, known as the <em>holdout</em> or <em>test</em> set, for use in testing predictive accuracy. The remaining data is the <em>training set</em>. For each of our competing models – in this case, competing values of <span class="math inline">\(\lambda\)</span> – we fit the model on the training set, then use the result to predict the test set. We then use whichever model does best in the test set.</p>
<p><em>Example: Million Song data</em></p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">library</span>(glmnet)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> glmOut <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(<span class="at">x=</span><span class="fu">as.matrix</span>(s50[,<span class="sc">-</span><span class="dv">1</span>]),<span class="at">y=</span>s50<span class="sc">$</span>V1,<span class="at">alpha=</span><span class="dv">0</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> glmOut</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    Lambda Index Measure     SE Nonzero</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>min <span class="fl">0.2474</span>   <span class="dv">100</span>   <span class="fl">89.44</span> <span class="fl">0.9201</span>      <span class="dv">90</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>1se <span class="fl">0.9987</span>    <span class="dv">85</span>   <span class="fl">90.28</span> <span class="fl">0.9823</span>      <span class="dv">90</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The <span class="math inline">\(\lambda\)</span> value that gave the smallest Mean Squared Prediction Error (MSE) as 0.2474. (Coincidentally, it was also the smallest value that the function tried; see <strong>glmOut$lambda</strong>.) A more conservative value of <span class="math inline">\(\lambda\)</span> was 0.9987, the largest <span class="math inline">\(\lambda\)</span> giving MSE within one standard error of the minimum; it’s conservative in the sense of being less likely to overfit; its MSE value, 90.28, was only slightly larger than the best one. In each case, all 90 predictors had nonzero coefficient estimates.</p>
</section>
<section id="sec-pgtn" class="level2" data-number="9.5">
<h2 data-number="9.5" class="anchored" data-anchor-id="sec-pgtn"><span class="header-section-number">9.5</span> Modern View</h2>
<p>There are many ways to deal with multicollinearity, which we must remind the reader only concerns <em>approximate</em> linear dependence pf the columns of <span class="math inline">\(A\)</span>. These days, many analysts go further, using ridge for situations in which there is <em>exact</em> linear dependence.</p>
<p>We saw such a setting in <a href="Ch4.html#sec-censusrref"><span>Section&nbsp;6.1</span></a>. There we deliberately induced exact linear dependence by inclusion of both male and female dummy variables. Let’s apply ridge:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(qeML) </span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(svcensus) </span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>svc <span class="ot">&lt;-</span> svcensus[,<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">4</span><span class="sc">:</span><span class="dv">6</span>)]  </span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>svc<span class="sc">$</span>man <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(svc<span class="sc">$</span>gender <span class="sc">==</span> <span class="st">'male'</span>) </span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>svc<span class="sc">$</span>woman <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(svc<span class="sc">$</span>gender <span class="sc">==</span> <span class="st">'female'</span>) </span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>svc<span class="sc">$</span>gender <span class="ot">&lt;-</span> <span class="cn">NULL</span> </span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>a <span class="ot">&lt;-</span> svc[,<span class="sc">-</span><span class="dv">2</span>] </span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>lambda <span class="ot">&lt;-</span> <span class="fl">0.1</span> </span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>a <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(a) </span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>tmp1 <span class="ot">&lt;-</span> <span class="fu">solve</span>(<span class="fu">t</span>(a) <span class="sc">%*%</span> a <span class="sc">+</span> lambda <span class="sc">*</span> <span class="fu">diag</span>(<span class="dv">4</span>)) </span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>tmp1 <span class="sc">%*%</span> <span class="fu">t</span>(a) <span class="sc">%*%</span> <span class="fu">as.matrix</span>(svc<span class="sc">$</span>wageinc) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>               [,1]
age        496.6716
wkswrkd   1372.7052
man     -18677.8751
woman   -29378.3086</code></pre>
</div>
</div>
<p>The results essentially are the same as what we obtained by having only one dummy, thus no linear dependence: Men still enjoy about an $11,000 advantage. But ridge allowed us to avoid deleting one of our dummies. Such deletion is easy in this case, but for large <span class="math inline">\(p\)</span>, say in the hundreds or even more, some analysts prefer the convenience of ridge.</p>
</section>
<section id="formalizing-the-notion-of-shrinkage" class="level2" data-number="9.6">
<h2 data-number="9.6" class="anchored" data-anchor-id="formalizing-the-notion-of-shrinkage"><span class="header-section-number">9.6</span> Formalizing the Notion of Shrinkage</h2>
<p>In the early 1980s, the statistical world was shocked by research by James and Stein that found, in short that:</p>
<blockquote class="blockquote">
<p>Say <span class="math inline">\(W\)</span> has <span class="math inline">\(q\)</span>-dimensional normal distribution with mean vector <span class="math inline">\(\mu\)</span> and independent components having variance <span class="math inline">\(\sigma^2\)</span>, each. We have a random sample of size <span class="math inline">\(n\)</span>, i.e.&nbsp;<span class="math inline">\(n\)</span> independent observations on <span class="math inline">\(W\)</span>. Then if <span class="math inline">\(q \geq 3\)</span>, in terms of Mean Squared Estimation Error, the best estimator of <span class="math inline">\(\mu\)</span> is NOT the sample mean <span class="math inline">\(\bar{W}\)</span>. Instead, it’s</p>
<p><span class="math display">\[
\left (
1 - \frac{(q-2) \sigma^2/n}{||\bar{W}||^2}
\right )
\bar{W}
\]</span></p>
</blockquote>
<p>The quantity within the parentheses is typically smaller than 1, giving us the shrinkage property. Note, though, that with larger <span class="math inline">\(n\)</span>, the amount of shrinkage is minor.</p>
<p>In the case of linear regression, shrinkage works there too, with <span class="math inline">\(q\)</span> being the number of columns in the <span class="math inline">\(A\)</span> matrix.</p>
<section id="shrinkage-through-length-penalization" class="level3" data-number="9.6.1">
<h3 data-number="9.6.1" class="anchored" data-anchor-id="shrinkage-through-length-penalization"><span class="header-section-number">9.6.1</span> Shrinkage through length penalization</h3>
<p>Say instead of minimizing <a href="Ch3.html#eq-matrixss">Equation&nbsp;<span>5.1</span></a>, we minimize</p>
<p><span id="eq-matrixssridge"><span class="math display">\[
(S - Ab)'(S - Ab) + \lambda ||b||^2
\tag{9.2}\]</span></span></p>
<p>The larger <span class="math inline">\(b\)</span> is, the harder it is to minimize the overall quantity <a href="#eq-matrixssridge">Equation&nbsp;<span>9.2</span></a>. We say that we <em>penalize</em> large values of <span class="math inline">\(b\)</span>, an indirect way of pursuing shrinkage. Now take the derivative and set to 0:</p>
<p><span class="math display">\[
0 = A'(S-Ab) + \lambda b
\]</span></p>
<p>i.e.</p>
<p><span class="math display">\[
(A'A + \lambda I) b = A'S
\]</span></p>
<p>and thus</p>
<p><span class="math display">\[
\widehat{\beta} = (A'A+\lambda I)^{-1} A'S
\]</span></p>
<p>It’s ridge! So here is formalization of our “almost singular” etc. language above to justify ridge as a shrinkage estimator..</p>
</section>
<section id="shrinkage-through-length-limitation" class="level3" data-number="9.6.2">
<h3 data-number="9.6.2" class="anchored" data-anchor-id="shrinkage-through-length-limitation"><span class="header-section-number">9.6.2</span> Shrinkage through length limitation</h3>
<p>Instead of penalizing <span class="math inline">\(||b||\)</span>, we could simply constrain it, i.e.&nbsp;we could set our optimization problem to:</p>
<blockquote class="blockquote">
<p>minimize <span class="math inline">\((S-Ab)'(S-Ab)\)</span>, subject to the constraint <span class="math inline">\(||b||^2 \leq \gamma\)</span></p>
</blockquote>
<p>We say that this new formulation is the <em>dual</em> of the first one. One can show that they are typically equivalent.</p>
</section>
</section>
<section id="the-lasso" class="level2" data-number="9.7">
<h2 data-number="9.7" class="anchored" data-anchor-id="the-lasso"><span class="header-section-number">9.7</span> The LASSO</h2>
<p>The LASSO (Least Absolute Shrinkage and Selection Operator) was developed by Robert Tibshirani in 1996, following earlier work by Leo Breiman. It takes <span class="math inline">\(\widehat{\beta}\)</span> to be the value of <span class="math inline">\(b\)</span> that minimizes</p>
<p><span id="eq-matrixsslasso"><span class="math display">\[
(S - Ab)'(S - Ab) + \lambda ||b||_1
\tag{9.3}\]</span></span></p>
<p>where the “l1 norm” is</p>
<p><span class="math display">\[
||b|| = \sum_{i=1}^p |b_i|
\]</span></p>
<p>We will write our original norm as <span class="math inline">\(||b||_2\)</span>.</p>
<p>This is a seemingly minor change, but with important implications. What Breiman and Tibshirani were trying to do was to obtain a <em>sparse</em> <span class="math inline">\(\widehat{\beta}\)</span> , i.e.&nbsp;a solution with lots of 0s, thereby providing a method for predictor variable selection. This is important because so-called “parsimonious” prediction models are desirable.</p>
<section id="properties" class="level3" data-number="9.7.1">
<h3 data-number="9.7.1" class="anchored" data-anchor-id="properties"><span class="header-section-number">9.7.1</span> Properties</h3>
<p>To that end, first note that it can be shown that, under some technical conditions, that the ridge solution minimizes</p>
<p><span class="math display">\[
(S - Ab)'(S - Ab)
\]</span></p>
<p>subject to the constraint</p>
<p><span class="math display">\[
||b||_2 \leq \gamma
\]</span></p>
<p>while in the LASSO case the constraint is</p>
<p><span class="math display">\[
||b||_1 \leq \gamma
\]</span></p>
<p>As with <span class="math inline">\(\lambda\)</span> in the original formulation, <span class="math inline">\(\gamma\)</span> is a positive number chosen by the analyst.</p>
</section>
</section>
<section id="ridge-vs.-lasso-for-dimension-reduction" class="level2" data-number="9.8">
<h2 data-number="9.8" class="anchored" data-anchor-id="ridge-vs.-lasso-for-dimension-reduction"><span class="header-section-number">9.8</span> Ridge vs.&nbsp;LASSO for Dimension Reduction</h2>
<p>Today’s large datasets being so common, we need a way to “cut things down to size,” i.e.&nbsp;<em>dimension reduction</em>, aimed at reducing the number of predictor variables. This is done both for the sake of simplicity and to over <em>overfitting</em>, in which fitting an overly complex model can reduce predictive power.</p>
<section id="geometric-view" class="level3" data-number="9.8.1">
<h3 data-number="9.8.1" class="anchored" data-anchor-id="geometric-view"><span class="header-section-number">9.8.1</span> Geometric view</h3>
<p>Comparison between the ridge and LASSO concepts is often done via this graph depicting the LASSO setting:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="LASSO_gray.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">LASSO sparsity</figcaption>
</figure>
</div>
<p>Here <span class="math inline">\(p = 2\)</span>, with <span class="math inline">\(b = (b_1,b_2)'\)</span>. The horizontal and vertical axes represent <span class="math inline">\(b_1\)</span> and <span class="math inline">\(b_2\)</span>.</p>
<ul>
<li><p>The constraint <span class="math inline">\(||b||_1 \leq \gamma\)</span> then takes the form of a diamond, with corners at <span class="math inline">\((\gamma,0)\)</span>, <span class="math inline">\((0,\gamma)\)</span>, <span class="math inline">\((-\gamma,0)\)</span> and <span class="math inline">\((0,-\gamma)\)</span>. The constraint <span class="math inline">\(||b||_1 \leq \gamma\)</span> requires us to choose a point <span class="math inline">\(b\)</span> somewhere in the diamond, including the boundary.</p></li>
<li><p>The concentric ellipses depict the values of <span class="math inline">\(c(b) = (S - Ab)'(S - Ab)\)</span>, as follows.</p></li>
<li><p>Consider one particular value of <span class="math inline">\(c(b)\)</span>, say 1.68.</p></li>
<li><p>Many different points <span class="math inline">\(b\)</span> in the graph will have <span class="math inline">\(c(b) = 1.68\)</span>; in fact, the locus of all such points is an ellipse.</p></li>
<li><p>There is one ellipse for each possible value of <span class="math inline">\(c(b)\)</span>. So, there are infinitely many ellipses, though only two are shown here.</p></li>
<li><p>Larger values of <span class="math inline">\(c(b)\)</span> yield larger ellipses.</p></li>
<li><p>On the one hand, we want to choose a <span class="math inline">\(b\)</span> for which <span class="math inline">\(c(b)\)</span> – our total squared prediction error – is small, thus a smaller ellipse.</p></li>
<li><p>But on the other hand, we need at least one point on the ellipse to be in common with the diamond.</p></li>
<li><p>The solution is then a point <span class="math inline">\(b\)</span> in which the ellipse just barely touches the diamond, respectively.</p></li>
</ul>
</section>
<section id="implication-for-dimension-reduction." class="level3" data-number="9.8.2">
<h3 data-number="9.8.2" class="anchored" data-anchor-id="implication-for-dimension-reduction."><span class="header-section-number">9.8.2</span> Implication for dimension reduction.</h3>
<p>The key point is that that “barely touching” point will be one of the four corners of the diamond, points at which either <span class="math inline">\(b_1 = 0\)</span> or <span class="math inline">\(b_2 = 0\)</span> – <em>hence a sparse solution</em>, meaning one in which many/most of the coefficients in the fitted model will be 0. This achieves the goal of dimension reduction.</p>
<p>Ridge will not produce a sparse solution. The diamond would now be a circle (not shown). The “barely touching point” will almost certainly will be at a place in which both <span class="math inline">\(b_1\)</span> and <span class="math inline">\(b_2\)</span> are nonzero. Hence no sparsity.</p>
</section>
<section id="avoidance-of-overfitting-without-dimension-reduction" class="level3" data-number="9.8.3">
<h3 data-number="9.8.3" class="anchored" data-anchor-id="avoidance-of-overfitting-without-dimension-reduction"><span class="header-section-number">9.8.3</span> Avoidance of overfitting <em>without</em> dimension reduction</h3>
<p>As we’ve seen, both ridge and LASSO reduce the size of the <span class="math inline">\(\widehat{\beta}\)</span> vector of estimated coefficients. Smaller quantities have smaller statistical variances, hence a guard against overfitting. So, even ridge can be employed as an approach to the overfitting problem, even though it does not provide a sparse solution.</p>
<p>On the other hand, in some settings, it may be desirable to keep all predictors, as seen in the next section.</p>
</section>
</section>
<section id="sec-useall" class="level2 page-columns page-full" data-number="9.9">
<h2 data-number="9.9" class="anchored" data-anchor-id="sec-useall"><span class="header-section-number">9.9</span> Example: NYC Taxi Data</h2>
<p>The purpose of this data is to predict trip time in the New York City taxi system. The <span class="math inline">\(qeML\)</span> package includes a 10,000-row subset.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(qeML)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(nyctaxi)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(nyctaxi)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>        trip_distance PULocationID DOLocationID tripTime DayOfWeek
2969561          1.37          236           43      598         1
7301968          0.71          238          238      224         4
3556729          2.80          100          263      761         3
7309631          2.62          161          249      888         4
3893911          1.20          236          163      648         5
4108506          2.40          161          164      977         5</code></pre>
</div>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(nyctaxi)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 10000     5</code></pre>
</div>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(<span class="fu">unique</span>(nyctaxi<span class="sc">$</span>PULocationID))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 143</code></pre>
</div>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(<span class="fu">unique</span>(nyctaxi<span class="sc">$</span>DOLocationID))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 205</code></pre>
</div>
</div>
<div class="page-columns page-full"><p>An old rule of thumb says that if we have <span class="math inline">\(p\)</span> predictors and <span class="math inline">\(n\)</span> data points, we should keep <span class="math inline">\(p &lt; \sqrt{n}\)</span> to avoid overfitting. As we will see in a later chapter, these days that rule is being questioned, but let’s see how it fits in here. In our case here, <span class="math inline">\(p = 1+143+205+1 = 350\)</span>, much larger than <span class="math inline">\(p = \sqrt{10000} = 100\)</span>. And if we are fitting a linear model, we may consider pickup/dropoff location interaction variables, basically products of the pickup and dropoff dummy variables. </p><div class="no-row-height column-margin column-container"><span class="">To avoid exact multicollinearity, we will use only 142 and 204 of the pickup and dropoff variables.</span></div></div>
<p>Thus we either should delete some of the pickup and dropoff variables, or use all of them but temper the fit using ridge. The latter may be more attractive, as riders would like a time estimate for their particular pickup and dropoff locations.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(glmnet)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>nycwide <span class="ot">&lt;-</span> <span class="fu">factorsToDummies</span>(nyctaxi[,<span class="sc">-</span><span class="dv">1</span>])</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>glmOut <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(<span class="at">x=</span>nycwide,<span class="at">y=</span>nyctaxi[,<span class="dv">1</span>],<span class="at">alpha=</span><span class="dv">0</span>)</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>glmOut</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:  cv.glmnet(x = nycwide, y = nyctaxi[, 1], alpha = 0) 

Measure: Mean-Squared Error 

    Lambda Index Measure      SE Nonzero
min 0.3002   100   2.943 0.07320     356
1se 0.6936    91   3.014 0.07558     356</code></pre>
</div>
</div>
</section>
<section id="a-warning" class="level2" data-number="9.10">
<h2 data-number="9.10" class="anchored" data-anchor-id="a-warning"><span class="header-section-number">9.10</span> A Warning</h2>
<p>Many statistical quantities now have <em>regularized</em>, i.e.&nbsp;shrunken versions. It is also standard practice in neural networks. This may be quite helpful in prediction contexts. However, note the following:</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
No Statistical Inference on Shrinkage Estimators
</div>
</div>
<div class="callout-body-container callout-body">
<p>Shrinkage produces a bias, of unknown size. Thus classical statistical inference (confidence intervals, hypothesis tests), e.g.&nbsp;those based on <a href="Ch3.html#eq-varcovar">Equation&nbsp;<span>5.7</span></a> for linear models, is not possible.</p>
</div>
</div>
</section>
<section id="your-turn" class="level2" data-number="9.11">
<h2 data-number="9.11" class="anchored" data-anchor-id="your-turn"><span class="header-section-number">9.11</span> Your Turn</h2>
<p>❄️ <strong>Your Turn:</strong> Show that <span class="math inline">\(A_{new}\)</span> in <a href="#sec-matform"><span>Section&nbsp;9.3.2</span></a> is of full rank, <span class="math inline">\(p\)</span>.</p>
<p>❄️ <strong>Your Turn:</strong> Consider a generalization of ridge regression, in which we find</p>
<p><span class="math display">\[
\textrm{argmin}_b ~
||{S} - {A} b||^2 + ||{D} b||^2
\]</span></p>
<p>for a diagonal matrix <span class="math inline">\(D\)</span>. The idea is to allow different shrinkage parameters for different predictor variables. Show that</p>
<p><span class="math display">\[
b =
{[{A}' {A} + {D}^2]}^{-1}
{A}' {S}
\]</span></p>
<p>❄️ <strong>Your Turn:</strong> In <a href="#sec-useall"><span>Section&nbsp;9.9</span></a>, it was pointed out that in some settings we may prefer to retain all of our predictor variables, rather than do dimension reduction, thus preferring ridge to LASSO. But we might pay a price for that preference, in that the LASSO may actually give us better predictive power. Write an R function to investigate this, with call form</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">compareRidgeLASSO</span>(data,yName)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>where <strong>data</strong> and <strong>yName</strong> are in the format of the predictive <span class="math inline">\(qeML\)</span> functions. Return the minimum Mean Squared Prediction Error for both algorithms.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./Ch5b.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Inner Product Spaces</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./Ch6a.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Eigenanalysis</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>