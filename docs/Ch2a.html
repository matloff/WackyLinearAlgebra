<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>4&nbsp; Covariance Matrices, MV Normal Distribution – Powered by Linear Algebra</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./Ch3.html" rel="next">
<link href="./Ch2.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-5e2915e4d4df5928b2b0a61215b328b6.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./Ch2a.html"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Covariance Matrices, MV Normal Distribution</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Powered by Linear Algebra</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">index.html</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Matrices and Vectors</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Matrix Inverse</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch2a.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Covariance Matrices, MV Normal Distribution</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Linear Statistical Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch3a.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Confidence Sets</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Matrix Rank</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch5a.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Vector Spaces</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch5b.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Inner Product Spaces</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch5bb.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Four Fundamental Spaces</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch5c.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Shrinkage Estimators</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch6a.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Eigenanalysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch6b.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Principal Components</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch6c.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Singular Value Decomposition</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch6d.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">A Deeper Look at Overfitting</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch8a.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Attention</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Contents</h2>
   
  <ul>
  <li><a href="#random-vectors" id="toc-random-vectors" class="nav-link active" data-scroll-target="#random-vectors"><span class="header-section-number">4.1</span> Random Vectors</a>
  <ul class="collapse">
  <li><a href="#sec-samplevspop" id="toc-sec-samplevspop" class="nav-link" data-scroll-target="#sec-samplevspop"><span class="header-section-number">4.1.1</span> Sample vs.&nbsp;population</a></li>
  </ul></li>
  <li><a href="#sec-cov" id="toc-sec-cov" class="nav-link" data-scroll-target="#sec-cov"><span class="header-section-number">4.2</span> Covariance</a>
  <ul class="collapse">
  <li><a href="#scalar-covariance" id="toc-scalar-covariance" class="nav-link" data-scroll-target="#scalar-covariance"><span class="header-section-number">4.2.1</span> Scalar covariance</a></li>
  <li><a href="#covariance-matrices" id="toc-covariance-matrices" class="nav-link" data-scroll-target="#covariance-matrices"><span class="header-section-number">4.2.2</span> Covariance matrices</a></li>
  </ul></li>
  <li><a href="#sec-mvn" id="toc-sec-mvn" class="nav-link" data-scroll-target="#sec-mvn"><span class="header-section-number">4.3</span> The Multivariate Normal Distribution Family</a>
  <ul class="collapse">
  <li><a href="#example-k-2" id="toc-example-k-2" class="nav-link" data-scroll-target="#example-k-2"><span class="header-section-number">4.3.1</span> Example: k = 2</a></li>
  <li><a href="#general-form" id="toc-general-form" class="nav-link" data-scroll-target="#general-form"><span class="header-section-number">4.3.2</span> General form</a></li>
  <li><a href="#properties" id="toc-properties" class="nav-link" data-scroll-target="#properties"><span class="header-section-number">4.3.3</span> Properties</a></li>
  </ul></li>
  <li><a href="#multinomial-random-vectors-have-approximate-multivariate-normal-distributions" id="toc-multinomial-random-vectors-have-approximate-multivariate-normal-distributions" class="nav-link" data-scroll-target="#multinomial-random-vectors-have-approximate-multivariate-normal-distributions"><span class="header-section-number">4.4</span> Multinomial Random Vectors Have Approximate Multivariate Normal Distributions</a></li>
  <li><a href="#your-turn" id="toc-your-turn" class="nav-link" data-scroll-target="#your-turn"><span class="header-section-number">4.5</span> Your Turn</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-covar" class="quarto-section-identifier"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Covariance Matrices, MV Normal Distribution</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div style="page-break-after: always;"></div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Goals of this chapter:
</div>
</div>
<div class="callout-body-container callout-body">
<p>A central entity in multivariate analysis is that of the <em>covariance matrix</em>. In this chapter we define the term, list its many properties, and show its role in the multivariate analog of the normal distribution family.</p>
</div>
</div>
<section id="random-vectors" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="random-vectors"><span class="header-section-number">4.1</span> Random Vectors</h2>
<p>You are probably familiar with the concept of a random variable, but of even greater importance is random <em>vectors</em>.</p>
<p>Say we are jointly modeling height, weight, age, systolic blood pressure and cholesterol, and are especially interested in relations between these quantities. We then have the random vector</p>
<p><span class="math display">\[
X
=
\left (
\begin{array}{r}
X_1 \\
X_2 \\
X_3 \\
X_4 \\
X_5 \\
  \end{array}
\right )
=
\left (
\begin{array}{r}
\textrm{height} \\
\textrm{weight} \\
\textrm{age} \\
\textrm{bp} \\
\textrm{chol} \\
  \end{array}
\right )
\]</span></p>
<section id="sec-samplevspop" class="level3" data-number="4.1.1">
<h3 data-number="4.1.1" class="anchored" data-anchor-id="sec-samplevspop"><span class="header-section-number">4.1.1</span> Sample vs.&nbsp;population</h3>
<p>We may observe <span class="math inline">\(n\)</span> realizations of <span class="math inline">\(X\)</span> in the form of sample data, say on <span class="math inline">\(n = 100\)</span> people. In the statistics world, we treat this data as a random sample from some population, say all Americans. Usually, we are just given the data rather then having actual random sampling, but this view recognizes that there are a lot more people out there than our data.</p>
<p>We speak of estimating population quantities. For instance, we can estimate the population value <span class="math inline">\(E(X_1)\)</span>, i.e.&nbsp;mean of <span class="math inline">\(X_1\)</span> throughout the population, by the sample analog,</p>
<p><span class="math display">\[
\frac{1}{n} \sum_{i=1}^n X_{1j}
\]</span></p>
<p>where <span class="math inline">\(X_{ij}\)</span> denotes the value of <span class="math inline">\(X_i\)</span> for the <span class="math inline">\(j^{th}\)</span> person in our sample.</p>
<p>By contrast, this view is rarely taken in the machine learning community. The data is the data, and the fact that it is a small subset of a much larger group is irrelevant. They will often allude to the randomness of the data by mentioning the “data generating mechanism,” but go no further.</p>
</section>
</section>
<section id="sec-cov" class="level2 page-columns page-full" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="sec-cov"><span class="header-section-number">4.2</span> Covariance</h2>
<section id="scalar-covariance" class="level3 page-columns page-full" data-number="4.2.1">
<h3 data-number="4.2.1" class="anchored" data-anchor-id="scalar-covariance"><span class="header-section-number">4.2.1</span> Scalar covariance</h3>
<p>Recall first the notion in statistics of <em>covariance</em>: Given a pair of random variables <span class="math inline">\(U\)</span> and <span class="math inline">\(V\)</span>, their covariance is defined by</p>
<p><span class="math display">\[
Cov(U,V) = E[(U - EU)(V - EV)]
\]</span></p>
<p>Loosely speaking, this measures the degree to which the two random variables vary together. Consider for instance human height <span class="math inline">\(H\)</span> and <span class="math inline">\(W\)</span>. Taller people tend to also be heavier. Say we sample many people from a population. Most of those who are taller than average, i.e.&nbsp;<span class="math inline">\(H &gt; EH\)</span>, will also be heavier than average, <span class="math inline">\(W &gt; EW\)</span>, making <span class="math inline">\((H - EH)(W - EW) &gt;
0\)</span>. Similarly, shorter people tend to be lighter, i.e.&nbsp;we often have <span class="math inline">\(H
&lt; EH\)</span> and <span class="math inline">\(W &lt; EW\)</span>, but then we still have <span class="math inline">\((H - EH)(W - EW) &gt; 0\)</span>. So, one way or the other, usually <span class="math inline">\((H - EH)(W - EW) &gt; 0\)</span>, and though there will be a number of exceptions, they will be rare enough so that</p>
<div class="page-columns page-full"><p><span class="math inline">\(E[(H - EH)(W - EW)] &gt; 0\)</span>.</p><div class="no-row-height column-margin column-container"><span class="">Of course, the <em>magnitude</em> of <span class="math inline">\((H - EH)(W - EW)\)</span> plays a role too.</span></div></div>
<p>In other words, <span class="math inline">\(Cov(H,W) &gt; 0\)</span>. Similarly if <span class="math inline">\(U\)</span> is often large when <span class="math inline">\(V\)</span> is small, and vice versa, we will likely have <span class="math inline">\(Cov(H,W) &lt; 0\)</span>.</p>
<p>If this sounds like correlation to you, then your hunch is correct. Covariance will indeed later lead to the concept of correlation, but that intuition will serve us now.</p>
<p>Note some properties of scalar covariance.</p>
<ul>
<li>Symmetry:</li>
</ul>
<p><span class="math display">\[
Cov(U,V) = Cov(V,U)
\]</span></p>
<ul>
<li><span class="math inline">\(Cov\)</span> is bilinear:</li>
</ul>
<p><span class="math display">\[
Cov(aU,bV) = ab ~ Cov(U,V)
\]</span></p>
<ul>
<li>Variance as a special case:</li>
</ul>
<p><span class="math display">\[
Cov(U,U) = Var(U)
\]</span></p>
<ul>
<li>Cross-product term:</li>
</ul>
<p><span id="eq-crossprod"><span class="math display">\[
Var(U+V) = Var(U) + Var(V) + 2 Cov(U,V)
\tag{4.1}\]</span></span></p>
<ul>
<li>“Short cut” formula:</li>
</ul>
<p><span id="eq-covuv"><span class="math display">\[
Cov(U,V) = E(UV) - (EU) (EV)
\tag{4.2}\]</span></span></p>
</section>
<section id="covariance-matrices" class="level3 page-columns page-full" data-number="4.2.2">
<h3 data-number="4.2.2" class="anchored" data-anchor-id="covariance-matrices"><span class="header-section-number">4.2.2</span> Covariance matrices</h3>
<p>The above was a review of the notion of covariance between two scalar random variables. We now turn to defining covariance for a random vector, which will turn out to be a matrix.</p>
<div class="page-columns page-full"><p>The relations between the various components of a random vector <span class="math inline">\(X\)</span> are often characterized by the <em>covariance matrix</em> of <span class="math inline">\(X\)</span>, whose entries consist of scalar covariances between pairs of components of a random vector.  It is defined as follows for a <span class="math inline">\(k\)</span>-component random vector <span class="math inline">\(X\)</span>. The covariance matrix, denoted by <span class="math inline">\(Cov(X)\)</span>, is a <span class="math inline">\(k \times k\)</span> matrix, and for <span class="math inline">\(1 \leq i,j \leq k\)</span>, its row <span class="math inline">\(i\)</span>, column <span class="math inline">\(j\)</span> element is</p><div class="no-row-height column-margin column-container"><span class="">The notation is somewhat overloaded. “Cov” refers both to the covariance between two random variables, say height and weight, and to the covariance matrix of a random vector. But it will always be clear from context which one is being discussed.</span></div></div>
<p><span class="math display">\[
Cov(X)_{ij} = Cov(X_i,X_j)
\]</span></p>
<p>As an example, here is data on major league baseball players:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(qeML) </span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(mlb1) </span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(mlb1) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>        Position Height Weight   Age
1        Catcher     74    180 22.99
2        Catcher     74    215 34.69
3        Catcher     72    210 30.78
4  First_Baseman     72    210 35.43
5  First_Baseman     73    188 35.71
6 Second_Baseman     69    176 29.39</code></pre>
</div>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>hwa <span class="ot">&lt;-</span> mlb1[,<span class="sc">-</span><span class="dv">1</span>] </span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">cov</span>(hwa) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>           Height    Weight        Age
Height  5.3542814  25.61130 -0.8239233
Weight 25.6113038 433.60211 12.9110576
Age    -0.8239233  12.91106 18.6145019</code></pre>
</div>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(hwa)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>            Height    Weight         Age
Height  1.00000000 0.5315393 -0.08252974
Weight  0.53153932 1.0000000  0.14371113
Age    -0.08252974 0.1437111  1.00000000</code></pre>
</div>
</div>
<p>Again, this is sample data. We find that the <em>sample estimate</em> of the covariance between height and weight is 25.61130.</p>
<p>We’ll be discussing more of this later, but what about that negative correlation between height and age? It’s near 0, and this could be a sampling artifact, but another possibility is that in this sport, shorter players do not survive as well.</p>
<p>Properties of the matrix version of covariance:</p>
<ul>
<li><p>Matrix form of definition:</p>
<p><span id="eq-matrixdef"><span class="math display">\[ Cov(X) = E[(X - X) (X - EX)']
\tag{4.3}\]</span></span></p>
<p>(Note the dimensions: <span class="math inline">\(X\)</span> is a column vector, say <span class="math inline">\(k \times 1\)</span>, so <span class="math inline">\((X - X) (X - EX)'\)</span> is <span class="math inline">\(k \times k\)</span>. The expected value is then of that size as well.)</p></li>
<li><p>For statistically independent random vectors <span class="math inline">\(Q\)</span> and <span class="math inline">\(W\)</span> of the same length,</p></li>
</ul>
<p><span id="eq-indepcov"><span class="math display">\[
Cov(Q+W) = Cov(Q) + Cov(W)
\tag{4.4}\]</span></span></p>
<ul>
<li>For any nonrandom scalar <span class="math inline">\(c\)</span>, and <span class="math inline">\(Q\)</span> a random vector, we have</li>
</ul>
<p><span class="math display">\[
Cov(cQ) = c^2 Cov(Q)
\]</span></p>
<ul>
<li><p>Say we have a random vector <span class="math inline">\(X\)</span>, of length <span class="math inline">\(k\)</span>, and a nonrandom matrix <span class="math inline">\(A\)</span> of size <span class="math inline">\(m \times k\)</span>. Then <span class="math inline">\(A X\)</span> is a new random vector <span class="math inline">\(Y\)</span> of <span class="math inline">\(m\)</span> components. It turns out that</p>
<p><span id="eq-acova"><span class="math display">\[
Cov(Y) = A Cov(X) A'
\tag{4.5}\]</span></span></p>
<p>The proof is straightforward but tedious, and will be omittted.</p></li>
<li><p><span class="math inline">\(Cov(X)\)</span> is a symmetric matrix. This follows from the symmetry of the definition.</p></li>
<li><p>The diagonal elements of <span class="math inline">\(Cov(X)\)</span> are the variances of the random variables <span class="math inline">\(X_i\)</span>. This follows from <span class="math inline">\(Cov(U,U) = Var(U)\)</span> for scalar <span class="math inline">\(U\)</span>.</p></li>
<li><p>If <span class="math inline">\(X\)</span> is a vector of length 1, i.e.&nbsp;a number, then</p></li>
</ul>
<p><span class="math display">\[
Cov(X) = Var(X)
\]</span></p>
<ul>
<li>For any length-<span class="math inline">\(k\)</span> column vector <span class="math inline">\(a\)</span>,</li>
</ul>
<p><span id="eq-quadform"><span class="math display">\[
Var(a'X) = a' ~ Cov(X) ~ a
\tag{4.6}\]</span></span></p>
<ul>
<li>Since variance is nonnegative, we thus see that <span class="math inline">\(Cov(X)\)</span> is <em>nonnegative definite</em>, meaning that for any length-<span class="math inline">\(k\)</span> column vector <span class="math inline">\(a\)</span></li>
</ul>
<p><span id="eq-covnndef"><span class="math display">\[
a' Cov(X) a \geq 0
\tag{4.7}\]</span></span></p>
<ul>
<li>More generally, for any compatible constant vectors <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>,</li>
</ul>
<p><span class="math display">\[
Cov(a'X,b'X) = a' Cov(X) b
\]</span></p>
<ul>
<li>For any constant (i.e.&nbsp;nonrandom) <span class="math inline">\(m \times k\)</span> matrix <span class="math inline">\(A\)</span>,</li>
</ul>
<p><span id="eq-covax"><span class="math display">\[
Cov(AX) = A Cov(X) A'
\tag{4.8}\]</span></span></p>
<!--
### Cross-covariance

The matrix $Cov(X)$ represents the covariance of a vector $X$
*with itself*. But we can also speak of the covariance of one vector $X$
with another vector $Y$, termed the *cross-covariance* between them.
Say $X$ and $Y$ are of lengths $m$ and $n$. Then $Cov(X,Y)$ will be of
size $m \times n$, with

$$
Cov(X,Y)_{ij} = Cov(X_i,Y_j)
$$

where the latter covariance is scalar.
-->
</section>
</section>
<section id="sec-mvn" class="level2 page-columns page-full" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="sec-mvn"><span class="header-section-number">4.3</span> The Multivariate Normal Distribution Family</h2>
<p>The familiar “bell-shaped curve” refers to the <em>normal</em> (or <em>Gaussian</em>) family, whose densities have the form</p>
<p><span class="math display">\[
\frac{1}{\sigma \sqrt{2 \pi}}
e^{-0.5 (\frac{t-\mu}{\sigma})^2}
\]</span></p>
<p>The values of <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> are the mean and standard deviation. But what if we have a random vector, say of length <span class="math inline">\(k\)</span>? Is there a generalized normal family?</p>
<section id="example-k-2" class="level3" data-number="4.3.1">
<h3 data-number="4.3.1" class="anchored" data-anchor-id="example-k-2"><span class="header-section-number">4.3.1</span> Example: k = 2</h3>
<p>The answer is yes. Here is an example for <span class="math inline">\(k = 2\)</span>:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Bell.png" class="img-fluid figure-img"></p>
<figcaption>3D bell density</figcaption>
</figure>
</div>
</section>
<section id="general-form" class="level3" data-number="4.3.2">
<h3 data-number="4.3.2" class="anchored" data-anchor-id="general-form"><span class="header-section-number">4.3.2</span> General form</h3>
<p>Well, then, what is the form of the <span class="math inline">\(k\)</span>-dimensional density function? Just as the univariate normal family is parameterized by mean and variance, the multivariate one is parameterized via mean <em>vector</em> <span class="math inline">\(\mu\)</span> and covariance <em>matrix</em> <span class="math inline">\(\Sigma\)</span>. The form is</p>
<p><span id="eq-mvndensity"><span class="math display">\[
(2\pi)^{-k/2} \det(\Sigma)^{-k/2}
e^{-0.5 (t-\mu)'(\Sigma)^{-1}(t-\mu)}
\tag{4.9}\]</span></span></p>
<p>Note the intuition:</p>
<ul>
<li><p>Instead of <span class="math inline">\(1/\sigma^2\)</span>, i.e.&nbsp;instead of dividing by variance, we “divide by <span class="math inline">\(\Sigma\)</span>,” intuitively viewing matrix inverse as a “reciprocal” of a matrix.</p></li>
<li><p>In other words, covariance matrices operate roughly like generalized variances.</p></li>
<li><p>Instead of squaring the scalar <span class="math inline">\(t - \mu\)</span>, we “square” it in the vector case by peforming a <span class="math inline">\(w'w\)</span> operation, albeit with <span class="math inline">\(\Sigma^{-1}\)</span> in the middle.</p></li>
</ul>
<p>Clearly, we should not stretch these analogies very far, but they do help our intuition here.</p>
</section>
<section id="properties" class="level3 page-columns page-full" data-number="4.3.3">
<h3 data-number="4.3.3" class="anchored" data-anchor-id="properties"><span class="header-section-number">4.3.3</span> Properties</h3>
<div id="thm-conditMVnormal" class="theorem">
<p><span class="theorem-title"><strong>Theorem 4.1</strong></span> If a random vector is multivariate (MV) normally distributed, then the conditional distribution of any one of its components <span class="math inline">\(Y\)</span>, given the others <span class="math inline">\(X_{others} = t\)</span> (note that <span class="math inline">\(t\)</span> is a vector if <span class="math inline">\(k &gt; 2\)</span>) has the following properties:</p>
<ul>
<li><p>It has a (univariate) normal distribution.</p></li>
<li><p>Its mean <span class="math inline">\(E(Y | X_{others} = t)\)</span> is linear in <span class="math inline">\(t\)</span>.</p></li>
<li><p>Its variance <span class="math inline">\(Var(Y | X_{others} = t)\)</span> does not involve <span class="math inline">\(t\)</span>.</p></li>
</ul>
<p>These of course are the classical assumptions of linear regression models: normality, linearity and homoskedasticity. They actually come from the MV normal model.</p>
<p>More generally: Denote the mean vector and covariance matrix a random vector <span class="math inline">\(X\)</span> by <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\Sigma\)</span>. Partition <span class="math inline">\(X\)</span> as</p>
<p><span class="math display">\[
\left (
\begin{array}{r}
X_1 \\
X_2 \\
\end{array}
\right )
\]</span></p>
<p>and partition <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\Sigma\)</span> similarly. The conditional distribution of <span class="math inline">\(X_1\)</span> given <span class="math inline">\(X_2 = t\)</span> is multivariate normal with these paramters:</p>
<p><span id="eq-condmean"><span class="math display">\[
E(X_1 | X_2 = t) =
\mu_1 + \Sigma_{12} \Sigma_{22}^{-1} (t - \mu_2)
\tag{4.10}\]</span></span></p>
<p><span id="eq-condcov"><span class="math display">\[
Cov(X_1 | X_2 = t) = \Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21}
\tag{4.11}\]</span></span></p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>This comes out of writing down the conditional density (overall density divided by marginal), and then doing some algebra.</p>
<p><span class="math inline">\(\square\)</span></p>
</div>
<p>Again, note the absence of <span class="math inline">\(t\)</span> in <a href="#eq-condcov" class="quarto-xref">Equation&nbsp;<span>4.11</span></a>.</p>
<p>Note too that the conditional covariance matrix, <span class="math inline">\(\Sigma_{11}\)</span> of <span class="math inline">\(X_1\)</span> given <span class="math inline">\(X_2\)</span>,</p>
<p><span class="math display">\[
\Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21}
\]</span></p>
<div class="page-columns page-full"><p> is “smaller” than the unconditional one, <span class="math inline">\(\Sigma_{11}\)</span>. <span class="math inline">\(X_1\)</span> varies less when we know something about <span class="math inline">\(X_2\)</span>.</p><div class="no-row-height column-margin column-container"><span class="">Of course, this is just a rough intuitive view. One matrix is not “smaller” than another. One way to make this mathematically rigorous is to say that the matrix <span class="math inline">\(B\)</span> is smaller than (or equal to) the matrix <span class="math inline">\(A\)</span> if <span class="math inline">\(A-B\)</span> is nonnegative definite, i.e.&nbsp;<span class="math inline">\(u'(A-B)u \geq 0\)</span> for all vectors <span class="math inline">\(u\)</span>. Since in this case <span class="math inline">\(A-B\)</span> is a covariance matrix, thus nonnegative definite (see <a href="#eq-covnndef" class="quarto-xref">Equation&nbsp;<span>4.7</span></a>), our intuitive statement would become rigorous under this definition.</span></div></div>
<div id="thm-xnormalthenaxnormal" class="theorem">
<p><span class="theorem-title"><strong>Theorem 4.2</strong></span> If <span class="math inline">\(X\)</span> is a multivariate-normal random vector, then so is <span class="math inline">\(AX\)</span> for any conformable nonrandom matrix <span class="math inline">\(A\)</span>.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>Again, perform direct evaluation of the density.</p>
<p><span class="math inline">\(\square\)</span></p>
</div>
<div id="thm-mvuvnormal" class="theorem">
<p><span class="theorem-title"><strong>Theorem 4.3 (Cramer-Wold Theorem)</strong></span> A random vector <span class="math inline">\(X\)</span> has a multivariate normal distribution if and only if <span class="math inline">\(w'X\)</span> has a univariate normal distribution for all conformable nonrandom vectors <span class="math inline">\(w\)</span>.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>“Only if” follows from above. “If” part too complex to present here.</p>
<p><span class="math inline">\(\square\)</span></p>
</div>
<div id="thm-mvclt" class="theorem page-columns page-full">
<p><span class="theorem-title"><strong>Theorem 4.4 (The Multivariate Central Limit Theorem)</strong></span> Let <span class="math inline">\(X_1, X_2,...\)</span> be a sequence on statistically independent random vectors, with common distribution having mean vector <span class="math inline">\(\mu\)</span> and covariance matrix <span class="math inline">\(\Sigma\)</span>, but not necessarily MV normal. Write</p>
<p><span class="math display">\[
\bar{X} = \frac{X_1+...+X_n}{n}
\]</span></p>
<p>Then the distribution of the random vector</p>
<p><span class="math display">\[
W_n = \sqrt{n} (\bar{X} - \mu)
\]</span></p>
<div class="page-columns page-full"><p>goes to multivariate normal with the 0 vector as mean and covariance matrix <span class="math inline">\(\Sigma\)</span>.</p><div class="no-row-height column-margin column-container"><span class="">The usual form would involve the “square root” of a matrix, but we will not discuss that concept until a later chapter.</span></div></div>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span><a href="#thm-mvuvnormal" class="quarto-xref">Theorem&nbsp;<span>4.3</span></a> reduces the problem to the univariate case, where we know the Central Limit Theorem holds.</p>
<p><span class="math inline">\(\square\)</span></p>
</div>
</section>
</section>
<section id="multinomial-random-vectors-have-approximate-multivariate-normal-distributions" class="level2 page-columns page-full" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="multinomial-random-vectors-have-approximate-multivariate-normal-distributions"><span class="header-section-number">4.4</span> Multinomial Random Vectors Have Approximate Multivariate Normal Distributions</h2>
<div class="page-columns page-full"><p>Recall that a <em>multinomial</em> random vector is the mathematial  analog of an R factor variable – a categorical variable with <span class="math inline">\(k\)</span> levels/categories. Just as a binomial random variable represents the number of “successes” in <span class="math inline">\(n\)</span> “trials,” a multinomial random vector represents the numbers of successes in each of the <span class="math inline">\(k\)</span> categories.</p><div class="no-row-height column-margin column-container"><span class="">To be consistent, view the binomial case as tabulating both successes and failures, e.g.&nbsp;both heads and tails in coin flips. Then from that viewpoint, the binomial case is multinomial with <span class="math inline">\(k=2\)</span>.</span></div></div>
<p>Let’s write such a random vector as</p>
<p><span class="math display">\[
X =
\left (
\begin{array}{r}
N_1 \\
... \\
N_k \\
\end{array}
\right )
\]</span></p>
<p>Let <span class="math inline">\(p_i\)</span> be the probability of a trial having outcome <span class="math inline">\(i=1,...,k\)</span>. Note the following:</p>
<ul>
<li><p><span class="math inline">\(N_1+...+N_k = n\)</span></p></li>
<li><p>The marginal distribution of <span class="math inline">\(N_i\)</span> is binomial, with success probability <span class="math inline">\(p_i\)</span> and <span class="math inline">\(n\)</span> trials.</p></li>
</ul>
<p>So for instance if we roll a fair die 10 times, then <span class="math inline">\(N_i\)</span> is the number of trials in which the roll’s outcome was <span class="math inline">\(i\)</span> dots and <span class="math inline">\(p_i = 1/6\)</span> , <span class="math inline">\(i=1,2,3,4,5,6\)</span>.</p>
<p>Let’s find <span class="math inline">\(Cov(X)\)</span>. Define the <em>indicator</em> vector</p>
<p><span class="math display">\[
I_i =
\left (
\begin{array}{r}
I_{i1} \\
... \\
I_{ik}  \\
\end{array}
\right )
\]</span></p>
<p>Here <span class="math inline">\(I_{ij}\)</span> is 1 or 0, depending on whether trial <span class="math inline">\(i\)</span> resulted in category <span class="math inline">\(j\)</span>. (A 1 “indicates” that caregory <span class="math inline">\(j\)</span> occurred.)</p>
<p>The key is that</p>
<p><span id="eq-sumindic"><span class="math display">\[
X = \sum_{i=1}^n I_i
\tag{4.12}\]</span></span></p>
<p>For instance, in the die-rolling example, the first component on the right-hand side is the number of rolls in which we got 1 dot, and that is by definition the same as <span class="math inline">\(N_1\)</span>, the first component of <span class="math inline">\(X\)</span>.</p>
<p>So there we have it – <span class="math inline">\(X\)</span> is a sum of independent, identically distributed random vectors, so by the Multivariate Central Limit Theorem, <span class="math inline">\(X\)</span> has an approximate multivariate normal distribution. Now, what are the mean vector and covariance matrix in that distribution?</p>
<p>From our discussion above, we know that</p>
<p><span class="math display">\[
EX =
\left (
\begin{array}{r}
np_1 \\
... \\
np_k \\
\end{array}
\right )
\]</span></p>
<p>What about <span class="math inline">\(Cov(X)\)</span>? Again, recognizing that <a href="#eq-sumindic" class="quarto-xref">Equation&nbsp;<span>4.12</span></a> is a sum of independent, identically distributed terms, <a href="#eq-indepcov" class="quarto-xref">Equation&nbsp;<span>4.4</span></a> tells us that</p>
<p><span class="math display">\[
Cov(X) = Cov(\sum_{i=1}^n I_i) = \sum_{i=1}^n Cov(I_i) = n Cov(I_1),
\]</span></p>
<p>that last equality reflecting that the <span class="math inline">\(I_i\)</span> are identically distributed (the trials all have the same probabilistic behavior).</p>
<p>Now to evaluate that covariance matrix, consider two specific elements <span class="math inline">\(I_{1j}\)</span> and <span class="math inline">\(I_{1m}\)</span> of <span class="math inline">\(I_1\)</span>. Recall, those elements are equal to 1 or 0, depending on whether the first trial results in Categories j and m, respectively. Then what is <span class="math inline">\(Cov(I_{1j},I_{1m})\)</span>? From <a href="#eq-covuv" class="quarto-xref">Equation&nbsp;<span>4.2</span></a>, we have</p>
<p><span id="eq-covjm"><span class="math display">\[
Cov(I_{1j},I_{1m}) = E(I_{1j} I_{1m}) - (EI_{1j}) (EI_{1m})
\tag{4.13}\]</span></span></p>
<p>Consider the two cases:</p>
<ul>
<li><span class="math inline">\(i=j\)</span>: Here <span class="math inline">\(E(I_{1j}^2) = E(I_{1j}) = p_j\)</span>. Thus</li>
</ul>
<p><span class="math display">\[
Cov(I_{1j},I_{1m}) = p_j (1-p_j)
\]</span></p>
<ul>
<li><span class="math inline">\(i \neq j\)</span>: Each <span class="math inline">\(I_r\)</span> consists of one 1 and <span class="math inline">\(k-1\)</span> 0s. Thus <span class="math inline">\(E(I_{1j} I_{1m}) = 0\)</span> and</li>
</ul>
<p><span class="math display">\[
Cov(I_{1j},I_{1m}) = -p_j p_m
\]</span></p>
</section>
<section id="your-turn" class="level2" data-number="4.5">
<h2 data-number="4.5" class="anchored" data-anchor-id="your-turn"><span class="header-section-number">4.5</span> Your Turn</h2>
<p>❄️ <strong>Your Turn:</strong> In <a href="#eq-mvndensity" class="quarto-xref">Equation&nbsp;<span>4.9</span></a> with <span class="math inline">\(k = 2\)</span>, write <span class="math inline">\(t = (t_1,t_2)\)</span>, and consider the quantity in the exponent,</p>
<p><span class="math display">\[
(t-\mu)'(\Sigma)^{-1}(t-\mu)
\]</span></p>
<p>Say we set this quantity to some constant <span class="math inline">\(c\)</span>, then graph the locus of points <span class="math inline">\(t\)</span> in the <span class="math inline">\(t_1,t_2\)</span> plane. What geometric figure would we get?</p>
<p>❄️ <strong>Your Turn:</strong> In <a href="#thm-conditMVnormal" class="quarto-xref">Theorem&nbsp;<span>4.1</span></a>, suppose</p>
<p><span class="math display">\[
\mu =
\left (
\begin{array}{r}
1.5 \\
8.0 \\
\end{array}
\right )
\]</span></p>
<p>and</p>
<p><span class="math display">\[
\Sigma =
\left (
\begin{array}{rr}
5.2 &amp; 6.2 \\
6.2 &amp; 20.1  \\
\end{array}
\right )
\]</span></p>
<p>Find the regression line</p>
<p><span class="math display">\[
\textrm{ mean Y } = a + bX
\]</span></p>
<p>❄️ <strong>Your Turn:</strong> Show that in the scalar context,</p>
<p><span class="math display">\[
Cov(X,Y) = E(XY) - EX ~ EY
\]</span></p>
<p>❄️ <strong>Your Turn:</strong> Show that in the vector context,</p>
<p><span class="math display">\[
Cov(X) = E(X X') - (EX) (EX)'
\]</span></p>
<p>❄️ <strong>Your Turn:</strong> Suppose</p>
<p><span class="math display">\[
W = X' \beta + \alpha S
\]</span></p>
<p>for a random vector <span class="math inline">\(X\)</span>, a scalar random variable <span class="math inline">\(S\)</span>, a nonrandom vector <span class="math inline">\(\beta\)</span> and a nonrandom scalar <span class="math inline">\(\alpha\)</span>. Show that</p>
<p><span class="math display">\[
Cov(W,S) = \beta' Cov(X,S) + \alpha Var(S)
\]</span></p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./Ch2.html" class="pagination-link" aria-label="Matrix Inverse">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Matrix Inverse</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./Ch3.html" class="pagination-link" aria-label="Linear Statistical Models">
        <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Linear Statistical Models</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>