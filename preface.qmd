
# Preface {.unnumbered} 

Welcome to my magnum opus! :-) I've written a number of books, but
consider this one to be the most important.  

## Subtlety in the Title

Let's start with the title of this book, *Powered by Linear Algebra: The
central role of matrices and vector spaces in Data Science*. It's
important to understand why the title is NOT "Linear Algebra for Data
Scientists." That latter would wrongly /connote that people in Data Science
(DS)will first learn linear algebra purely as a branch of math in this
book, with no hint of connections to DS, then apply that knowledge in
subsequent DS courses. Instead, the goal in the title is to emphasize
the fact that:

> Linear algebra is absolutely fundamental to the Data Science field.
> For us data scientists, it is "our" branch of math.  Almost every
> concept in this book is first motivated by a Data Science application.
> Mastering this branch of math, which is definitely within the reach of
> all, pays major dividends.

## Philosophy

*I learned very early the difference between knowing the name of
something and knowing something* -- physicist Richard Feynman 

*...it felt random.  "Follow these steps and you get the
result you are looking for." But why does it work?  What possessed you
to follow this path as opposed to any other? How might I have come up
with this myself?* -- [comment](https://loreley.one/2024-09-pca) by
a reader of a famous linear algebra book

This book does not allow rote memorization, merely "knowing
the name of something." The focus on How? and Why? is on every page.

A fundamental philosophy of my book here is to avoid reader
frustration. It's easy to define, say the dimension of a vector
subspace, but that's definitely not enough. What is the underlying
intuition? Why is the concept important, especially in Data Science?

The presentation of each concept in this book begins with a problem to
be solved, almost always from Data Science, then leading up to a linear
algebra solution.  Basically, the math sneaks up on the reader, who
suddenly realizes they've just learned a new general concept! And the
reader knows where the concept fits into the Big Picture, and can
distill the abstraction into an intuitive summary.

Examples:

* In Chapter 1, we use Markov chain transition matrices and network graph
  models (e.g. social networks) to motivate the notion of a matrix and
  matrix multiplication. An interest in finding the stationary
  distribution of a Markov chain then leads to the concept of matrix
  inverses. (Linear models are presented later, after groundwork of matrix
  rank is laid.) 

* The chapter on matrix rank starts with a dataset right off the bat, and
  shows that R's linear model function **lm** fails if categorical
  variables are fully specified. This motivates the notion of rank, and
  the dataset dovetails with the theory throughout the chapter, which
  culminates in a proof that row rank equals column rank.

* The chapter on eigenanalysis begins with explaining the goals of PCA
  (with a real dataset). We derive the first PC as a constrained
  maximization of variance, and behold! -- the solution turns out to
  have the form $Ax = \lambda x$! So eigenanalysis comes from solving a
  Data Science problem. PCA is later covered in detail in the following
  chapter, but with this motivation we develop the properties of
  eigenvalues and eigenvectors in the current chapter.

Furthermore, our presentation of the linear algebra connections to Data
Science goes far beyond the "obvious" ones of linear models, PCA and
SVD. We discussion recommender systems, for instance, not only in
connection to SVD and the like, but also as an application of shrinkage
estimators.

## Who Is This Book For?

Of course the book should work very well as a classroom textbook. If a Data
Science or Statistics program requires linear algebra offered by a Math
Department, the level and content of this book should be similar to that
math course, but with much better student motivation due to the Data
Science emphasis of the book.  The "applications first" approach is key
to that motivational power.

Actually, the applications-centered nature of the book should make
teaching the course more rewarding for instructors as well, and the use
of Quarto enables easy conversion to Powerpoint by instructors.

I also hope the book's emphasis on the How? and Why? especially
appeals to do-it-yourselfers, those whose engagement in self-study is
motivated by intellectual curiosity rather than a course grade.

## Prerequisite Background

Basic data science:

* Calculus.  

* Some exposure to R is recommended, but the text can be read
without it.[For a quick, painless introduction to R, see my
[fasteR](https://github.com/matloff/fasteR) tutorial, say the first 8
lessons.]{.column-margin}

* Basics of random variables, expected value and variance.

## The Role of Theory (and R)

::: {.callout-important}

## This book is "mathematical but not very theoretical."

Theorems are mainly limited to results with practical importance, and
proofs are sometimes rather informal. But the subject matter is indeed
mathematical. The goal is to develop in the reader mathematical skill
and intuition into this powerful tool, rather than coding of linear algebra
methods.

Thus the many R examples are meant to make the mathematical concepts
concrete. But this is definitely not an "how to do linear algebra in R"
book.  In the software context, the Feynman quote above might be, "There
is a difference between knowing how to use code libraries for something
and knowing the core nature of that thing." That said, the code examples
do serve a vital role. 

:::

## R Packages Used

``` r
qeML
glmnet
igraph
dsld
networkdata
pracma
regclass
WackyData
```

## Data Availabilty

The datasets used are included with the above packages. 

```{r}
#| include: false
library(dsld)
library(qeML)
```

## Web Site

*github.com/matloff/WackyLinear Algebra*

## Edition Number

Currently 1.0.0. Correction of typos etc. will usually increment the
third digit.

## Permission to Copy

This work is licensed under Creative Commons Zero v1.0 Universal.

## Thanks

I deeply appreciate feedback from: Mike Hannon, Nick
Knueppel, Joe Rickert and Noah Perry.



