

```{r}
#| include: false
library(dsld)
library(qeML)
```

{{< pagebreak >}}

# Matrices and Vectors

::: {.callout-note}

## Goals of this chapter:

The two main structures in linear algebra are *matrices* and *vector
spaces*. We begin the book with the former, introduced in this chapter,
motivating matrix multiplication and presenting several applications.

:::

In this chapter, we will take as our main application *Markov chains*,
a statistical model having wide applications in medicine, economics and
so on. It is very simple to explain, thus making it a good choice for
introducing matrices.

## A Random Walk Model

Let's consider a *random walk* on {1,2,3,4,5} in the number line. Time
is numbered 1,2,3,... Our current position is termed our *state*. The
notation X~k~ = i means that at time k we are in state/position i.

Our rule will be that at any time k, we flip a coin. If we are currently
at position i, we move to either i+1 or i-1, depending on whether the
coin landed heads or tails. The exceptions are k = 1 and k = 5, in which
case we stay put if tails or move to the adjacent position if heads.

We can summarize the probabilities with a *matrix*, a two-dimensional
array:

$$
P_1 =
\left (
\begin{array}{rrrrr}
0.5 & 0.5 & 0 & 0 & 0\\
0.5 & 0 & 0.5 & 0 & 0\\
0 & 0.5 & 0 & 0.5 & 0\\
0 & 0 & 0.5 & 0 & 0.5\\
0 & 0 & 0 & 0.5 & 0.5 \\
\end{array}
\right )
$$

For instance, look at row 2. There are 0.5 values in columns 1 and 3,
meaning there is a 0.5 chance of a move 2 $\rightarrow$ 1, and a 0.5
chance of a move 2 $\rightarrow$ 3.

We use a subscript 1 here in $P_1$, meaning "one step." We go from, say,
state 2 to state 1 in one step with probability 0.5. $P_1$ is called the
*one-step transition matrix* (or simply the *transition matrix*) for
this process.  

Note that each row in a transition matrix must sum to 1.  After all,
from state i we must go *somewhere*.

What about the two-step transition matrix $P_2$? For instance, what
should be in the row 3, column 1 position in that matrix?  From state 3,
we could go to state 1 in two steps, by two tails flips of the coin.
The probability of that is $0.5^2 = 0.25$. So the row 3, column 1
element in $P_2$ is 0.25. On the other hand, if from state 3 we flip
tails then heads, or heads then tails, we are back to state 3. So, the
row 3, column 3 element in  $P_2$ is 0.25 + 0.25 = 0.5.

The reader should verify the correctness here:


$$
P_2 =
\left (
\begin{array}{rrrrr}
0.5 & 0.25 & 0.25 & 0 & 0\\
0.25 & 0.5 & 0 & 0.25 & 0\\
0.25 & 0 & 0.5 & 0 & 0.25\\
0 & 0.25 & 0 & 0.5 & 0.25\\
0 & 0 & 0.25 & 0.25 & 0.5 \\
\end{array}
\right )
$$

Well, finding two-step transition probabilities would be tedious in
general, but it turns out that is a wonderful shortcut: Matrix
multiplication. We will cover this in the next section, but first a
couple of preliminaries.

The above random walk is a *Markov chain*. The Markov Property says that
the system "has no memory." If say we land at position 2, we will go to
1 or 3 with probability 1/2 *no matter what the previous history of the
system was*; it doesn't matter *how* we got to state 3. That in turn
comes in this example from the independence of the successive coin flips.

**Notation:** Individual elements of a matrix are usually written with
double subscripts. For instance, a~25~ will mean the row 2,
column 5 element of the matrix $A$. If say $A$ has more than 9 rows, 
its row 11, column 5 element is denoted by a~11,5~, using the comma to
avoid ambiguity.

## Vectors

Matrices are two-dimensional arrays. One-dimensional arrays are called
*vectors*, either in row or column form, e.g.

$$
u = (12,5,13)
$$

and

$$
u = 
\left (
\begin{array}{r}
12 \\
5 \\
13 \\
\end{array}
\right )
$$

Please note:

* Vectors may also be viewed as one-row or one-column matrices.

* When not otherwise stated, the term "vector" will mean column form.

* The term *scalar* simply means a number, rather than a matrix or
vector. It will be used quite frequently in this book.

## Addition and Scalar Multiplication{#sec-easyops}

Vectors of the same length may be summed, in elementwise form, e.g.

$$
\left (
\begin{array}{r}
12 \\
5 \\
13 \\
\end{array}
\right )
+
\left (
\begin{array}{r}
-3 \\
6 \\
18.2 \\
\end{array}
\right ) =
\left (
\begin{array}{r}
9 \\
11 \\
31.2 \\
\end{array}
\right )
$$

Similarly, two matrices may be added, again in elementwise fashion,
provided the number of rows is the same for both, as well as the same
condition for number of columns.

Vectors and matrices can be multiplied by scalars, again elementwise,
e.g.

$$
0.3
\left (
\begin{array}{r}
6 \\
15 \\
\end{array}
\right ) =
\left (
\begin{array}{r}
1.8 \\
4.5 \\
\end{array}
\right ) 
$$

## Matrix-Matrix Multiplication

This is the most fundamental operation in linear algebra. It is defined
as follows:


> Given matrix $A$ of $k$ rows and $m$ columns and
> matrix $B$ of $m$ rows and $r$ columns, the product $C = AB$ is
> a $k \textrm{ x } m$ matrix, whose row $i$, column $j$ element is
> 
> $$
> a_{i1} b_{1j} +
> a_{i2} b_{2j} + ... +
> a_{im} b_{mj} 
> $$
> 
> This is the "dot product" of row $i$ of A and column $j$ of B:  Find the
> products of the paired elements in the two vectors, then sum.

For example, set 

$$
A = \left (
\begin{array}{rrr}
5 & 2 & 6 \\
1 & 1 & 8 \\
\end{array}
\right )
$$

and

$$
B = \left (
\begin{array}{rr}
5 & -1 \\
1 & 0 \\
0 & 8 \\
\end{array}
\right )
$$

Let's find the row 2, column 2 element of $C = AB$.  Again, that means
taking the dot product of row 2 of $A$ and $column$ 2 of $B$, which we've
highlighted below.

$$
A = \left (
\begin{array}{rrr}
5 & 2 & 6 \\
\color{red}{1} & \color{red}{1} & \color{red}{1} \\
\end{array}
\right )
$$

and

$$
B = \left (
\begin{array}{rr}
5 & \color{red}{-1} \\
1 & \color{red}{0} \\
0 & \color{red}{8} \\
\end{array}
\right )
$$

The value in question is then

1 (-1) + 1 (0) + 1 (8) = 7

Let's check it, with R:

```{r}
a <- rbind(c(5,2,6),c(1,1,1))
b <- cbind(c(5,1,0),c(-1,0,8))
a %*% b
```

The **rbind** and **cbind** functions ("row bind" and "column bind") are
very handy tools for creating matrices.
The reader should make sure to check the other elements by hand.

::: {#tip-conformable .callout-tip}  

Always keep in mind that in the matrix product $AB$, the number of rows
of $B$ must equal the number of columns of $A$. The two matrices are
then said to be *conformable*.

::: 

## The Identity Matrix

The *identity matrix* $I$ of size $n$ is the $n \textrm{ x } n$ matrix
with 1s on the diagonal and 0s elsewhere.  $IB = B$ and $AI = A$ for any
conformable $A$ and $B$.

## Application to Markov Chain Transition Matrices {#sec-introMCs}

Now let's return to the question of how to easily compute $P_2$,
the two-step transition matrix. It turns out that:

> Let P denote the transition matrix of a (finite-state) Markov chain. The
> k-step transition matrix is $P^k$.

At first, this may seem amazingly fortuitous, but it makes sense in
light of the "and/or" nature of the probability computations involved.
Recall our computation for the row 1, column 2 element of $P_2$ above.
From state 1, we could either stay at 1 for one flip, then move to 2 on
the second flip, or we could go to 2 then return to 1. Each of these has
probability 0.5, so the total probability is

$$
(0.5)(0.5) + (0.5)(0.5)
$$

But this is exactly the form of our "dot product" computation
in the definition of matrix multiplication,

$$
a_{i1} b_{i1} +
a_{i2} b_{i1} + ... +
a_{m1} b_{m1} 
$$

Then $P^3$ stores the 3-step probabilities and so on.


Statisticians and computer scientists like to look at the *asymptotic*
behavior of systems, meaning what happens to a quantity when time or
size or some other value grows.  Let's see where we might be after say, 6
steps:

```{r}
matpow <- function(m,k) {
   nr <- nrow(m)
   tmp <- diag(nr)  # identity matrix
   for (i in 1:k) tmp <- tmp %*% m
   tmp
}

p1 <- rbind(c(0.5,0.5,0,0,0), c(0.5,0,0.5,0,0), c(0,0.5,0,0.5,0), 
   c(0,0,0.5,0,0.5), c(0,0,0,0.5,0.5))
matpow(p1,6) 
```

So for instance if we start at position 2, there is about an 11% chance
that we will be at position 3 at time 6. What about time 25?

```{r}
matpow(p1,25)
```

So, no matter which state we start in, at time 25 we are about 20%
likely to be at any of the states. In fact, as time $n$ goes to infinity,
this probability vector becomes exactly (0.20,0.20,0.20,0.20,0.20).
It will be shown below that the vector of long-run state probabilities $\nu$ is
the solution of 

$$
P \nu = \nu
$${#eq-stationMarkov}

where $P$ is the transition matrix for the Markov chain.

## Network Graph Models

There has always been lots of analysis of "Who is connected to whom,"
but activity soared after the advent of Facebook and the film, *A Social
Network.*  See for instance *Statistical Analysis of Network Data with R*
by Eric Kolaczy and Gábor Csárdi. As the authors say, 

> The oft-repeated statement that “we live in a connected world” perhaps
> best captures, in its simplicity why networks have come to hold 
> such interest in recent years. From on-line social networks like
> Facebook to the World Wide Web and the Internet itself, we are
> surrounded by examples of ways in which we interact with each other.
> Similarly, we are connected as well at the level of various human
> institutions (e.g., governments), processes (e.g., economies), and
> infrastructures (e.g., the global airline network). And, of course,
> humans are surely not unique in being members of various complex,
> inter-connected systems.  Looking at the natural world around us, we see
> a wealth of examples of such systems, from entire eco-systems, to
> biological food webs, to collections of inter-acting genes or
> communicating neurons.

And of course, at the center of it all is a matrix! Here is why:

Let's consider the famous Karate Club dataset:

[]{.column-margin} 

```{r}
# remotes::install_github("schochastics/networkdata") 
library(networkdata)
data(karate)
library(igraph)
plot(karate)
```

There is a link between node 13 and node 4, meaning that club members 13
and 4 are friends.[This graph is *undirected*, as friendship is mutual.
Many graphs are *directed*, but we will assume undirected
here.]{.column-margin}

Specifically, the *adjacency matrix* has row i, column j element as 1 or
0, according to whether a link exists between nodes i and j.

```{r}
adjK <- as_adjacency_matrix(karate)
adjK
adjK[13,4]
```

Accordingly, row 13, column 4 does have a 1 entry.

As is the case with Markov transition matrices, powers of an adjacency
matrix can yield valuable information. In the Markov case,
multiplication gives us sums of paired products, computing
probabilities. What about the network graph case? 

Here products are of the form 0x0, 0x1, 1x0 or 1x1.  If there is a
nonzero entry m in row i, column j of the square of the adjacency
matrix, that means there were m 1x1 products in that sum, which would
correspond to m paths. Let's look into this.

```{r}
adjK2 <- adjK %*% adjK
```

We see that **adjK2[11,1]** is 2. Inspection of **adjK** shows that its
row 11, columns 6 and 7 are 1s, and that rows 6 and 7, column 1 are 1s
as well. So there are indeed two two-hop paths from node 11 to node 1,
specifically $11 \rightarrow 6 \rightarrow 1$ and 
$11 \rightarrow 7 \rightarrow 1$. Thus the 2 we see in **adjK2[11,1]**
was correct.

In other words, $A^k$ for a network adjacency matrix $A$ shows the
number of paths from each node to each of the others.

Actually, what is typically of interest is *connectivity* rather than
number of paths. For any given pair of nodes, is there a multihop path
between them?  Or does the graph break down to several "islands" of
connected nodes?

Again consider the karate club data.

```{r}
u <- matpow(adjK,33)
sum(u == 0)
```

So, in that graph representing paths of 33 links, there are no 0s.
In this graph, no pair of nodes has 0 paths between them. The graph
is connected.

Making this kind of analysis fully correct requires paying attention to
things such as cycles.  The details are beyond the scope of this book.

## Recommender Systems{#sec-recsys}

If you inquire about some item at an online store, the software will
also present you with some related items that it thinks would be of
interest to you.  How does the software make this guess?

Clearly, the full answer is quite complex. But we can begin to see the
process by looking at some real data.

```{r}
site <- 'http://files.grouplens.org/datasets/movielens/ml-100k/u.data'
q <- read.table(site)
names(q) <- c('user','movie','rating','userinfo')
head(q)
```

We see for instance that user 22 gave movie 242 a rating of 1. If we
want to know some characteristics of this user, his/her ID is 878887116,
which we can find in the file **u.user** at the above URL. Other files
tell us more about this movie, e.g. its genre, and so on.

Let's explore the data a bit:

How many users and movies are in this dataset?

```{r}
length(unique(q$user))
length(unique(q$movie))
```

How many other users rated movie number 242?

```{r}
sum(q$movie == 242)
```

Did user 22 rate movie 234, for instance?

```{r}
which(q$user == 22 & q$movie == 234)
```

Now we can begin to see a solution to the recommender problem. Say we
wish to guess whether user 22 would like movie 234. We could look for
other users who have rated many of the same movies as user 22, then
focus on the ones who rated movie 234.  We could average those ratings
to obtain a predicted rating for movie 234 by user 22.[We could also
incorporate the characteristics of user 22 and the others, which may
improve our prediction accuracy, but we will not pursue that
here.]{.column-margin}

In order to assess interuser similarity of the nature described above,
we might form a matrix $S$, as follows. There would be 943 rows, one
for each user, and 1682 columns, one for each movie. The element in row
$i$, column $j$ would be the rating user $i$ gave to movie $j$. Most of
the matrix would be 0s.

The point of constructing $S$ is that determining the similarity of
users becomes a matter of measuring similarity of rows of $S$. This
paves the way to exploiting the wealth of matrix-centric methodology we
will develop in this book.

## Matrix Algebra

### Other basic operations

Matrix multiplication may seem odd at first, but other operations are
straightforward.

**Addition:** We just add corresponding elements. For instance,

$$
A = \left (
\begin{array}{rrr}
5 & 2 & 6 \\
1 & 2.6 & -1.2 \\
\end{array}
\right )
$$

$$
B = \left (
\begin{array}{rrr}
0 & 20 & 6 \\
3 & 5.8 & 1 \\
\end{array}
\right )
$$

$$
A+B = \left (
\begin{array}{rrr}
5 & 22 & 12 \\
4 & 8.4 & -0.2 \\
\end{array}
\right )
$$

We do have to make sure the addends match in terms of numbers of rows
and columns, 2 and 3 in the example here.

**Scalar multiplication:** Again, this is simply elementwise. E.g. with
A as above,

$$
1.5 A = \left (
\begin{array}{rrr}
7.5 & 3 & 9 \\
1.5 & 3.9 & -1.8 \\
\end{array}
\right )
$$

**Distributive property:**

For matrices A, B and C of suitable conformability (A and B match in
numbers of rows and columns, and their common number of columns matches
the number of rows in C), we have

(A+B) C = AC + BC

### Matrix transpose{#sec-transpose}

This is a very simple but very important operation: We merely exchange
rows and columns of the given matrix. For instance, with A as above, its
transpose (signified with "'"), is

$$
A' = \left (
\begin{array}{rr}
5 & 1 \\
2 & 2.6 \\
6 & -1.2 \\
\end{array}
\right )
$$

Some books use the notation $A^t$ or $A^T$ instead of $A'$.
The R function for transpose is **t()**.

It can be shown that if $A$ and $B$ are conformable, then

$$
(AB)' = B'A'
$$

For some matrices $C$, we have $C' = C$. $C$ is then termed *symmetric*.

We will often write a row vector in the form (a,b,c,...). So
(5,1,88) means the 1x3 matrix with those elements. If we wish this to
be a column vector, we use transpose, so that for instance (5,1,88)'
means a 3x1 matrix.

### Trace of a square matrix{#sec-trace}

The *trace* of a square matrix $A$ is the sum of its diagonal elements,
$tr(A) = \sum_{i=1}^n A_{ii}$. This measure has various properties, some
obvious (trace of the sum is sum of the traces), and some less so, such
as:

> Suppose $A$ and $B$ are square matrices of the same size. Then
> 
> $$
> tr(AB) = tr(BA)
> $${#eq-traceab}
> 
> *Proof:* See Your Turn problem.

And furthermore:

<blockquote>

It can be shown that trace is invariant under *circular
shifts*, e.g. $UVW$, $VWU$ and $WUV$ all have the same trace.

</blockquote>

# Partitioned Matrices: an Invaluable Visualization Tool

Here, "visualization" is not a reference to graphics but rather to
highlighting certain submatrices.

::: {#tip-partitioned .callout-tip}  

## Crucial Tool

The techniques introduced in this section will be used throughout the
book. Readers should spend extra time here, devising some of their own
examples.

:::

## How It Works

Consider a matrix-vector product Mv. Of course, that means that v is a
column vector whose length is equal to the number of columns of M. If M
is of size rxs, then v is sx1.

Let's denote column j of M by C<sub>j</sub>.  Then we will see later in
this chapter that 

$$
Mv = 
v_1 C_{1} +
v_2 C_{2} + ... +
v_s C_{s}  
$$

For instance, take 

$$
A = \left (
\begin{array}{rrr}
5 & 2 & 6 \\
1 & 2.6 & -1.2 \\
\end{array}
\right )
$$

and 

$$
v = \left (
\begin{array}{r}
10 \\
2 \\
1 \\
\end{array}
\right )
$$

The reader should check that

$$
10 \left (
\begin{array}{r}
5 \\
1 \\
\end{array}
\right )
+
2 \left (
\begin{array}{r}
2 \\
2.6 \\
\end{array}
\right )
+
1 \left (
\begin{array}{r}
6 \\
-1.2 \\
\end{array}
\right )
= Av
$$

where the latter is

$$
\left (
\begin{array}{r}
60 \\
14  \\
\end{array}
\right )
$$

Note that the above expression,

$$
10 \left (
\begin{array}{r}
5 \\
1 \\
\end{array}
\right )
+
2 \left (
\begin{array}{r}
2 \\
2.6 \\
\end{array}
\right )
+
1 \left (
\begin{array}{r}
6 \\
-1.2 \\
\end{array}
\right ),
$$

is a sum of scalar products of vectors, which is called a *linear
combination* of those vectors. The quantities 10, 2 and 1 are the
*coefficients* in that linear combination.

In other words, we have that:

<blockquote>

The product $Av$ of a matrix times a column vector is equal to a linear
combination of the columns of the matrix, with coefficients equal to the
column vector.

</blockquote>

Similarly,

<blockquote>

The product $wA$ of a row vector and a matrix is equal to a linear
combination of the rows of the matrix, with the coefficients coming from
the row vector.

</blockquote>

To further illustrate partitioned matrices, write the above matrix $A$
as 

$$
A = 
\left (
\begin{array}{rr}
A_{11} & A_{21} \\
\end{array}
\right )
$$

where 

$$
A_{11} = 
 \left (
 \begin{array}{rr}
 5 & 2 \\
 1 & 2.6 \\
 \end{array}
 \right )
$$

and  


$$
A_{12} = 
 \left (
 \begin{array}{r}
 6 \\
 -1.2 \\
 \end{array}
 \right )
$$

Symbolically, $A$ now looks like a 1x2 "matrix." Similarly, writing

$$
v = 
 \left (
 \begin{array}{r}
 v_{11} \\
 v_{21} \\
 \end{array}
 \right )
$$

where 

$$
 v_{11} = 
 \left (
 \begin{array}{r}
 10 \\
 2 \\
 \end{array}
 \right )
 $$

and $v_{21} = 1$ (a 1x1 matrix), $v$ looks to be 2x1.

So, again pretending, treat the product $Av$ as the multiplication of a
1x2 "matrix" and 2x1 "vector", yielding a 1x1 result,

$$
A_{11} v_{11} + A_{12} v_{21}
$$

But all that pretending actually does give the correct answer!

$$
A_{11} v_{11} + A_{12} v_{21} =
 \left (
 \begin{array}{rr}
 5 & 2 \\
 1 & 2.6 \\
 \end{array}
 \right ) 
 \left (
 \begin{array}{r}
 10 \\
 2 \\
 \end{array}
 \right )
+
 \left (
 \begin{array}{r}
 6 \\
 -1.2 \\
 \end{array}
 \right )
1 
=
 \left (
 \begin{array}{r}
 60 \\
 14 \\
 \end{array}
 \right )
$$

We can extend that reasoning further. Say $A$ and $B$ are matrices of
sizes $m \textrm{x} n$ and $n \textrm{x} k$, and consider the product
$AB$. Partition $B$ by its columns,

$$
B = (B^{(1)},B^{(2)},..., B^{(k)})
$$ 

Now pretending that $A$ is a $1 \textrm{x} 1$ "matrix" and $B$ is 
a$1 \textrm{x} k$ "matrix", we have

$$
AB = (AB^{(1)},AB^{(2)},..., AB^{(k)})
$$

In other words,

<blockquote>

In the product $AB$, column $j$ is a linear combination of the columns
of $A$, and the coefficients in that linear combination are the elements
of column $j$ of $B$.

A similar result holds for the row of the product.

</blockquote>

❄️  **Your Turn:** Write out the details of that "similar result."

# A Further Look at Markov Chains

Suppose $X_0$, our state at time 0, is random. Let $f$ denote its
distribution, i.e. its list of probabilities:
$f_i = P(X_0 = i)$, i = 1,...,k, where k is the number
of states in the chain. What about $X_1$, the state at time 1?
Let's find an expression for $g$, the distribution of $X_1$.[This
section will be longer than previous ones, but will bring together many
of the concepts. The reader's patience here will be an investment paying
great dividends in the sequel.]{.column-margin}

$$
g_j = P(X_1 = j)
= \sum_{i=1}^k P(X_0 = i) P(X_1 = j | X_0 = i)
= \sum_{i=1}^k f_i a_{ij}
$$

where $a_{ij}$ is the row i, column j element of the chain's transition
matrix $P$.

For example, consider $g_5$. How could we be at state 5 at time 1? We
could start in state 1, probability $f_1$, then move to state 5,
probability $a_{15}$, for a total probability of $f_1 a_{15}$. 
Or, we could start in state 2, probability $f_2$, then move to state 5,
probability $a_{25}$, for a total probability of $f_2 a_{25}$.
And so on.

So,

$$
g_j = \sum_{i=1}^k f_i a_{ij}
$$

Putting this is more explicit matrix terms,

$$
g = \left (
\begin{array}{r}
g_1 \\
g_2 \\
... \\
g_k \\
\end{array}
\right )
=
\left (
\begin{array}{r}
f_1 a_{11} + f_2 a_{21} + ... + f_k a_{k1} \\
f_1 a_{12} + f_2 a_{22} + ... + f_k a_{k2} \\
... \\
f_1 a_{1k} + f_2 a_{2k} + ... + f_k a_{kk} \\
\end{array}
\right )
$$

That last expression is

$$
f'P
$$

so we have the nice compact relation for the distribution of $X_1$ in
terms of the distribution of $X_0$.[By the way, it won't be used here, but
just for practice, note that the right-hand side, Pf, here is
a linear combination of the columns of P, from our above material on
partitioning.]{.column-margin}

$$
g' = f'P
$$


And setting h to the distribution of $X_2$, the same reasoning gives us

$$
h' = g'P 
$$

Then since $g' = f'P$, we have
[Note that we used the Markov property, 
"memorylessness." Once we reach time 1, "time starts over," regradless
of the previous history, i.e. regardless of where we were at time 0.]{.column-margin}

$$
h' = f'P^2 
$$

and so on. Iterating, we obtain

$$
d_j' = d_0' P^j 
$$

where $d_i$ is the distribution of $X_i$.

Similarly, 

$$
d_j' = d_{j-1}' P
$$

For convenience, let's take transposes:[Recall that $(AB)' =
B'A'$.]

$$
d_j = P' d_{j-1}
$$

Now suppose our chain as a long-run distribution, as in {@sec-introMCs}.
Let's call that distribution $\nu$. By lettting $j \rightarrow \infty$
above, we have

$$
\nu = P' \nu
$$

Since P is known, this provides us with a way to compute $\nu$. Yes,
finding a high power of P would do this too, but that would involve a lot
of computation, and even then it would not yield the exact answer. We
will return to this in the next chapter. 

## Application: Google PageRank{#sec-pagerank}

When Google was first formed, its key internal component was a method to
rank Web sites in terms of popularity.  They developed such a method,
and named it PageRank, a pun combining the term *Web page* (i.e. Web
site) and the name of one of the founders, Larry Page. It's based on a
Markov model.

The transition matrix is modeled as follows. row $i$ has $o_i$ nonzero
entries, each of which is equal to $1/o_i$.  They define popularity as
the resulting long-run distribution, i.e.  $\nu$ in @sec-introMCs.

## Random Vectors

You are probably familiar with the concept of a random variable, but of
even greater importance is random *vectors*.

Say we are jointly modeling height, weight, age, systolic blood pressure
and cholesterol, and are especially interested in relations between
these quantities.  We then have the random vector

$$
 X 
=
 \left (
 \begin{array}{r}
 X_1 \\
 X_2 \\
 X_3 \\
 X_4 \\
 X_5 \\
  \end{array}
 \right )
=
 \left (
 \begin{array}{r}
 \textrm{height} \\
 \textrm{weight} \\
 \textrm{age} \\
 \textrm{bp} \\
 \textrm{chol} \\
  \end{array}
 \right )
$$

### Sample vs. population

We may observe $n$ realizations of $X$ in the form of sample data, say
on $n = 100$ people. In the statistics world, we treat this data as a
random sample from some population, say all Americans. Usually, we are
just given the data rather then having actual random sampling, but this
view recognizes that there are a lot more people out there than our
data.

We speak of estimating population quantities. For instance, we can
estimate the population value $E(X1), i.e. mean of $X_1$ throughout the
population, by the sammple analog,

$$
\frac{1}{n} \sum_{i=1}^n X_{1j}
$$

where $X_{ij}$ denotes the value of $X_i$ for the $j^{th}$ person in our
sample.

By contrast, this view is rarely taken in the machine learning
community. The data is the data, and the fact that it is a small subset
of a much larger group is irrelevant. They will often allude to the
randomness of the data by mentioning the "data generating mechanism."

## Your Turn

❄️  **Your Turn:** The long-run probabilities in @sec-introMCs turned out to be
uniform, with value 0.20 for all five states. In fact, that is usually
not the case.  Make a small change to $P_1$ -- remember to keep the row
sums to 1 -- and compute a high power to check whether the long-run
distribution seems nonuniform.

❄️  **Your Turn:** Not every Markov chain, even ones with finitely
many states, have long-run distributions. Some chains have *periodic*
states. It may be, for instance, that after leaving state $i$, once can
return only after an even number of hops. Modify our example chain here
so that states 1 and 5 (and all the others) have that property. Then
compute $P^n$ for various large values of $n$ and observe oscillatory
behavior, rather than long-run convergence.

❄️  **Your Turn:** Consider the following model of a discrete-time,
single-server queue:

* Model parameters are p (probability of job completion), q 
  (probability of new job arriving) and m (size of the buffer).

* Jobs arrive, are served (possibly after queuing) and leave.

* Only one job can be in service at a time.

* At each time epoch:

    * The job currently in service, if any, will complete with
      probability p.

    * Slightly after a possible job completion, a job in the queue,
      if any, will start service.

    a Slightly after that, anew job will arrive with probability q.
      If the queue is empty, this job starts service. If not, and if the
      queue is not full, it will join the queue.  Otherwise, the job is
      discarded.

* The system is memoryless.

* The current state is the number of jobs in the system, taking on the
values 0,1,2,..,m+1; that last state means m jobs in the queue and 1 in
service.

For instance, say p = 0.4, q = 0.2, m = 5, Suppose the current state is
3, so there is a job in service and two jobs in the queue. Our next
state will be 2 with probability (0.4) (0.8); it will be 3 with
probability (0.4) (0.2), and so on.

Analyze this system for the case given above.` Find the approximate
long-run distribution, and also the proportion of jobs that get
discarded.

❄️  **Your Turn:** Write a function with call form

``` r
makeSimilarityMatrix(m)
```

❄️  **Your Turn:** Prove @eq-traceab.  Hint: Write out the left-hand side
as a double sum.  Reverse the order of summation, and work toward the
right-hand side.

