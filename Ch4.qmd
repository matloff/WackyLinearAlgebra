
```{r}
#| include: false
library(dsld)
library(qeML)
```

{{< pagebreak >}}

# Matrix Rank, and Vector Spaces 

In our computations in the latter part of the last chapter, we added a
proviso that $(A'A)^{-1}$ exists. In this chapter, we'll present a
counterexample, which will naturally lead into our covering matrix rank and
the basics of vector spaces.

## Example: Census Data{#sec-censusrref}

This dataset is also from **qeML**. It is data for Silicon Valley
engineers in the 2000 Census. Let's focus on just a few columns.

```{r}
data(svcensus) 
head(svcensus) 
svc <- svcensus[,c(1,4:6)] 
head(svc) 
lm(wageinc ~ .,data=svc) 
```

So, we estimate that, other factors being equal, men about paid close to
\$11,000 more than women. This is a complex issue, but for our purposes
here, how did **gender** become **gendermale**, no explicit mention of
women?

Let's try to force the issue:

```{r}
svc$man <- as.numeric(svc$gender == 'male')
svc$woman <- as.numeric(svc$gender == 'female')
svc$gender <- NULL
head(svc)
lm(wageinc ~ .,data=svc)
```

Well, we couldn't force the issue after all. Why not? We hinted above
that $A' A$ may not be invertible. Let's check its row-reduced form.

```{r}
A <- cbind(1,svc[,-2])
A <- as.matrix(A)
ApA <- t(A) %*% A
ApA
```

Is this matrix invertible? Let's apply the elementary row operations
introduced in {@pencilpaper}:

```{r}
library(pracma)
rref(ApA) 
```

Aha! The row operations process ended prematurely. This matrix has no
inverse. We say that the matrix has *rank* 4, when it needs to be 5;
we also say that $A'A$ is not of *full rank*. We will return to this
point shortly, but first we formalize introduce the row operations
process.

## Reduced Row Echelon Form of a Matrix

We formalize and extend @sec-pencilpaper:

Elementary row operations:

* Multiply a row by a constant.

* Add a multiple of one row to another.

* Swap two rows.

Again, each operation can be implemented via pre-multiplying the given
matrix by a corresponding elementary matrix. The latter is the result of
applying the given operation to the identity matrix $I$.

By applying these operations to a matrix $A$, we can compute its
*reduced row echelon form* $A_{rref}$, which is defined by the following
properties:

* Each row, if any, consisting of all 0s is at the bottom of the matrix.

* The first nonzero entry in a row, called the *pivot*, is a 1.

* Each pivot will be to the right of the pivots in the rows above it.

* All entries below a pivot are 0.

* Each pivot is the only nonzero entry in its column.

The reader should verify that the matrix at the end of Section
{@censusrref} has these properties.

## Census Data Example, Continued

There is a lot here that is directly related to important general
issues.

### Linear dependent/independent vectors

Recall that in the nonfull rank example we presented in @sec-noinverse,
one row was double another, 

row 1 - 2 row 1 = 0

In the census example,

```{r}
head(A)
```

the sum of the last two columns of $A$ was equal to the first column:

column 1 - column 4 - column 5 = 0

We say are *linearly dependent* if some linear combination of them
equals 0, as in both cases above. If no nontrival linear combination of
the vectors is 0 (the linear combination whose coefficients are all 0 is
trivally equal to 0), we say the vectors are *linearly independent*.

### Major relevance

As we will see, linear dependence of the rows or columns is the culprit
in non-full rank matrices. This is a major issue for linear models, in
which an inverse is necessary. 

Moreover, in many cases a matrix will technically be invertible, but
"approximately" nonfull rank. This can wreak havoc in linear models.

The reader can see, then, that understanding of matrix rank is key. That
in turn will require understanding of vector spaces. The current chapter is
devoted to these concepts, which are used heavily in the sequel.

### Bounds on ranks

It is surprising that not only was $A'A$ not of full rank, but
so was $A$:

```{r}
qr(ApA)$rank
qr(A)$rank
```

Yet this is rather startling. $A$ has over 20,000 rows --- yet only 4
linearly independent ones?[There are many subsets of 4 rows that are
linearly independent. But no sets of 5 or more are linearly independent.
]{.column-margin} But it follows from this fact:

<blockquote>

For any $r \textrm{x} s$ matrix $G$, the rank of $G$ is less than or equal to 
$\min(r,s)$.

</blockquote>

We will see shortly why this is true.

## Vector Spaces



